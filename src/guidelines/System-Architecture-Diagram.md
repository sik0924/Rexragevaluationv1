# REX 시스템 목표 모델 & V1.0 구현 범위

> **작성일**: 2025-10-16  
> **목적**: 내부 보고서용 시스템 아키텍처 및 구현 범위 정의  
> **V1.0 출시 목표**: 2025-11-30

---

## 📋 목차

1. [전체 목표 모델](#1-전체-목표-모델)
2. [시스템 마인드맵](#2-시스템-마인드맵)
3. [메뉴 구성도](#3-메뉴-구성도)
4. [시스템 아키텍처 도식화](#4-시스템-아키텍처-도식화)
5. [V1.0 구현 범위](#5-v10-구현-범위)
6. [V2.0 이후 로드맵](#6-v20-이후-로드맵)

---

## 1. 전체 목표 모델

### 1.1 핵심 비전

**"자동화된 RAG 성능 평가 및 개선 순환 체계 구축"**

```
┌─────────────────────────────────────────────────────────────────┐
│                        REX 핵심 가치                             │
├─────────────────────────────────────────────────────────────────┤
│  ✅ 정확한 평가    │  ✨ 자동 개선    │  💰 비용 최적화      │
│  - 12개 RAG 지표  │  - LLM Judge     │  - 샘플링 전략       │
│  - 다각도 측정     │  - 근본 원인 분석 │  - 90% 비용 절감    │
│  - 실시간 모니터링 │  - 최적 설정 탐색 │  - 예산 관리        │
└─────────────────────────────────────────────────────────────────┘
```

### 1.2 3대 목표

#### 🎯 목표 1: 정확하고 포괄적인 RAG 성능 평가

- **12개 핵심 지표**를 통한 다각도 성능 측정
- 실시간 모니터링 및 진행 상황 추적
- 점수 분포, 케이스별 분석, 비교 분석 제공

#### 🎯 목표 2: 자동화된 성능 개선 루프

- **Phase 1**: LLM Judge 기반 근본 원인 분석
- **Phase 2**: 자동 개선안 생성
- **Phase 3**: 최적 설정 탐색 (그리드 서치/베이지안 최적화)

#### 🎯 목표 3: 비용 효율성 극대화

- 휴리스틱 + 샘플링 전략으로 **LLM Judge 호출 90% 절감**
- 실시간 비용 추적 및 예산 관리
- 비용 최적화 제안 자동 생성

---

## 2. 시스템 마인드맵

### 2.1 REX 전체 기능 마인드맵

```
                            ┌─────────────┐
                            │     REX     │
                            │  RAG 성능   │
                            │  평가 시스템 │
                            └──────┬──────┘
                                   │
                ┌──────────────────┼──────────────────┐
                │                  │                  │
         ┌──────▼──────┐    ┌─────▼─────┐    ┌──────▼──────┐
         │ 일반 사용자  │    │  관리자    │    │  비용 관리   │
         │   기능      │    │   기능     │    │    기능     │
         └──────┬──────┘    └─────┬─────┘    └──────┬──────┘
                │                 │                  │
       ┌────────┼────────┐        │         ┌────────┼────────┐
       │        │        │        │         │        │        │
   ┌───▼───┐┌──▼──┐┌───▼───┐ ┌───▼────┐┌──▼──┐ ┌───▼───┐┌──▼──┐
   │데이터셋││평가 ││결과   │ │시스템  ││사용자│ │비용   ││예산 │
   │ 관리  ││실행 ││분석   │ │리소스  ││계정 │ │추적   ││관리 │
   └───┬───┘└──┬──┘└───┬───┘ └───┬────┘└──┬──┘ └───┬───┘└─────┘
       │       │       │         │        │        │
   ┌───▼───────▼───────▼─────────▼────────▼────────▼───┐
   │                                                     │
   │  ┌──────────┐  ┌──────────┐  ┌──────────┐         │
   │  │ CSV/JSON │  │ 실시간   │  │ LLM Judge│         │
   │  │  업로드   │  │모니터링  │  │근본 원인 │         │
   │  └──────────┘  └──────────┘  │  분석    │         │
   │                               └──────────┘         │
   │  ┌──────────┐  ┌──────────┐  ┌──────────┐         │
   │  │ 자동 생성│  │ 12개 지표│  │ 샘플링   │         │
   │  │          │  │  평가    │  │  전략    │         │
   │  └──────────┘  └──────────┘  └──────────┘         │
   │                                                     │
   │  ┌──────────┐  ┌──────────┐  ┌──────────┐         │
   │  │ 점수 분포│  │ 케이스   │  │ 비교     │         │
   │  │ 시각화   │  │  분석    │  │  분석    │         │
   │  └──────────┘  └──────────┘  └──────────┘         │
   │                                                     │
   └─────────────────────────────────────────────────────┘
```

### 2.2 핵심 기능 트리

```
REX
│
├─ 📊 데이터 관리
│  ├─ 데이터셋 생성/업로드
│  │  ├─ 수동 입력
│  │  ├─ CSV/JSON 파싱
│  │  └─ 자동 생성 (LLM)
│  ├─ 데이터 검증
│  │  ├─ 필수 필드 체크
│  │  ├─ 형식 검증
│  │  └─ 중복 제거
│  └─ 버전 관리
│     ├─ 변경 이력 추적
│     └─ 롤백 기능
│
├─ ⚡ 평가 실행
│  ├─ 평가 설정
│  │  ├─ 12개 지표 선택
│  │  ├─ LLM Judge 모델 설정
│  │  ├─ 샘플링 전략 구성
│  │  └─ 비용 예측
│  ├─ 실시간 모니터링
│  │  ├─ 진행률 추적 (QA별, 지표별)
│  │  ├─ 실시간 점수 업데이트
│  │  ├─ 에러 발생 추적
│  │  └─ 비용 누적 추적
│  └─ 평가 이력
│     ├─ 과거 평가 목록
│     ├─ 필터링/검색
│     └─ 상태별 조회
│
├─ 📈 결과 분석
│  ├─ 점수 분포 시각화
│  │  ├─ 히스토그램
│  │  ├─ 박스플롯
│  │  └─ 트렌드 차트
│  ├─ 낮은 점수 케이스 분석
│  │  ├─ 임계값 기반 필터링
│  │  ├─ LLM Judge 근본 원인 분석
│  │  └─ 개선 제안 생성
│  └─ 비교 분석
│     ├─ 여러 평가 비교
│     ├─ 설정 차이 분석
│     └─ 성능 개선률 계산
│
├─ ✨ 자동 개선
│  ├─ Phase 1: 근본 원인 분석
│  │  ├─ 휴리스틱 1차 필터링
│  │  ├─ 고정 비율 샘플링
│  │  └─ LLM Judge 분석
│  ├─ Phase 2: 개선안 생성
│  │  ├─ 원인별 설정 매핑
│  │  └─ 3-5개 설정 조합 생성
│  └─ Phase 3: 최적 설정 탐색
│     ├─ 그리드 서치 (V1.0)
│     ├─ 베이지안 최적화 (V2.0)
│     └─ 성능 비교 및 선정
│
├─ 💰 비용 관리
│  ├─ 실시간 비용 추적
│  │  ├─ 토큰 사용량 카운팅
│  │  ├─ 제공사별 비용 집계
│  │  └─ 지표별 비용 분석
│  ├─ 예산 관리
│  │  ├─ 예산 한도 설정
│  │  ├─ 알림 임계값 설정
│  │  └─ Hard Limit 적용
│  └─ 최적화 제안
│     ├─ 샘플링 전략 추천
│     ├─ 모델 전환 제안
│     └─ 지표 선택 최적화
│
└─ 🔧 관리자 기능
   ├─ 시스템 리소스 모니터링
   │  ├─ CPU/메모리 사용량
   │  ├─ 디스크 I/O
   │  └─ 네트워크 트래픽
   ├─ 사용자 계정 관리
   │  ├─ 권한 설정 (RBAC)
   │  ├─ 활동 로그
   │  └─ 사용량 제한
   ├─ LLM/VectorDB 관리
   │  ├─ API 키 설정
   │  ├─ 모델 목록 관리
   │  └─ 연결 테스트
   └─ 로그 조회
      ├─ 시스템 이벤트
      ├─ 에러 추적
      └─ 평가 이력
```

### 2.3 사용자 여정 마인드맵

```
                   ┌──────────────┐
                   │   로그인     │
                   └──────┬───────┘
                          │
                   ┌──────▼───────┐
                   │ 통합 대시보드 │
                   └──────┬───────┘
                          │
        ┌─────────────────┼─────────────────┐
        │                 │                 │
   ┌────▼────┐      ┌─────▼─────┐    ┌─────▼─────┐
   │신규 평가│      │기존 평가  │    │시스템     │
   │시작하기│      │결과 확인  │    │관리       │
   └────┬────┘      └─────┬─────┘    └─────┬─────┘
        │                 │                 │
   ┌────▼────────────┐    │            ┌────▼─────┐
   │1. 데이터셋 선택 │    │            │비용 확인 │
   └────┬────────────┘    │            └──────────┘
        │                 │            ┌──────────┐
   ┌────▼────────────┐    │            │사용자    │
   │2. 평가 환경 설정│    │            │관리      │
   │  - 지표 선택    │    │            └──────────┘
   │  - LLM Judge   │    │            ┌──────────┐
   │  - 샘플링      │    │            │리소스    │
   └────┬────────────┘    │            │모니터링  │
        │                 │            └──────────┘
   ┌────▼────────────┐    │
   │3. 평가 실행     │    │
   │  - 실시간 모니터│    │
   │  - 진행률 추적  │    │
   └────┬────────────┘    │
        │                 │
   ┌────▼────────────┐    │
   │4. 결과 분석     │◄───┘
   │  - 점수 분포    │
   │  - 케이스 분석  │
   │  - 개선 제안    │
   └────┬────────────┘
        │
        ├─────────────┐
        │             │
   ┌────▼────┐  ┌────▼──────┐
   │결과 비교│  │자동 개선  │
   └─────────┘  │워크플로우 │
                └───────────┘
```

---

## 3. 메뉴 구성도

### 3.1 전체 메뉴 계층 구조

```
REX
│
├─ 🏠 통합 대시보드 (Dashboard)
│  └─ 전체 평가 현황, 최근 활동, 주요 지표 요약
│
├─ ⚡ 평가 시작 (New Evaluation)
│  ├─ 1단계: 데이터셋 선택
│  ├─ 2단계: 평가 환경 설정
│  │  ├─ 지표 선택 (12개)
│  │  ├─ LLM Judge 설정
│  │  └─ 샘플링 전략
│  └─ 3단계: 비용 예측 및 실행
│      └─ → 실시간 모니터링 (Monitor)
│          └─ → 평가 결과 (Results)
│
├─ 📊 평가 모니터링 (Monitoring)
│  ├─ 진행 중인 평가 목록
│  ├─ 상태별 필터 (진행중/완료/실패/대기)
│  └─ → 상세 모니터링 (Monitor)
│
├─ 📜 평가 이력 (History)
│  ├─ 과거 평가 목록
│  ├─ 필터링 (날짜, 상태, 데이터셋)
│  ├─ 검색 기능
│  └─ → 평가 결과 (Results)
│      ├─ 점수 분포 시각화
│      ├─ 지표별 상세 분석
│      ├─ 낮은 점수 케이스 분석
│      └─ 개선 제안
│
├─ 🔍 결과 비교 (Comparison)
│  ├─ 여러 평가 선택 (최대 4개)
│  ├─ 지표별 성능 비교
│  ├─ 설정 차이 분석
│  └─ 성능 개선률 계산
│
├─ 🗂️ 데이터셋 관리 (Datasets)
│  ├─ 데이터셋 목록
│  ├─ 생성/업로드
│  │  ├─ 수동 생성
│  │  ├─ CSV/JSON 업로드
│  │  └─ 자동 생성 (LLM)
│  ├─ 편집/삭제
│  └─ 버전 관리
│
├─ ✨ 자동 개선 (Auto Improve)
│  ├─ 설정 (Setup)
│  │  ├─ 기준 평가 선택
│  │  ├─ LLM Judge 활성화
│  │  ├─ 실험 횟수 설정
│  │  └─ 최적화 목표 설정
│  ├─ → 진행 (Progress)
│  │  ├─ Phase 1: 근본 원인 분석
│  │  ├─ Phase 2: 개선안 생성
│  │  └─ Phase 3: 최적 설정 탐색
│  └─ → 결과 (Results)
│      ├─ 최적 설정 확인
│      ├─ 성능 개선률
│      ├─ 실험 비교
│      └─ 설정 적용
│
├─ 💰 비용 대시보드 (Costs)
│  ├─ 비용 요약
│  │  ├─ 총 비용 (30일)
│  │  ├─ 평가당 평균
│  │  └─ 예산 사용률
│  ├─ 탭 메뉴
│  │  ├─ 개요 (Overview)
│  │  │  ├─ 비용 추이 차트
│  │  │  ├─ LLM 제공사별 비용
│  │  │  └─ 지표별 비용
│  │  ├─ 비용 분석 (Breakdown)
│  │  │  └─ 평가별 상세 비용
│  │  ├─ 예산 관리 (Budget)
│  │  │  └─ 예산 목록 및 상태
│  │  └─ 최적화 제안 (Optimize)
│  │      └─ 비용 절감 방안
│  ├─ → 예산 설정 (Budget Settings)
│  │  ├─ 예산 생성/수정
│  │  ├─ 알림 임계값 설정
│  │  └─ Hard Limit 설정
│  └─ → 비용 알림 (Cost Alerts)
│      ├─ 알림 목록
│      ├─ 임계값 초과 알림
│      └─ 최적화 권장사항
│
└─ 🛡️ 관리자 (Admin) ⚠️ 관리자 전용
   ├─ 시스템 개요
   │  ├─ 리소스 사용량
   │  ├─ 활성 사용자
   │  └─ 평가 통계
   ├─ 탭 메뉴
   │  ├─ 리소스 모니터링
   │  │  ├─ CPU/메모리
   │  │  ├─ 디스크 I/O
   │  │  └─ 네트워크
   │  ├─ 사용자 관리
   │  │  ├─ 계정 목록
   │  │  ├─ 권한 설정
   │  │  └─ 활동 로그
   │  └─ LLM/VectorDB 관리
   │      ├─ API 키 관리
   │      ├─ 모델 목록
   │      └─ 연결 테스트
   └─ → 시스템 로그 (Logs)
      ├─ 로그 검색/필터
      ├─ 심각도별 분류
      └─ 시간대별 조회
```

### 3.2 페이지 네비게이션 플로우

```
┌─────────────┐
│   Login     │
└──────┬──────┘
       │
       ▼
┌─────────────────────────────────────────────────────────┐
│                    Main Navigation                       │
│  ┌────────┬────────┬────────┬────────┬────────┬────────┐│
│  │Dashboard│ New   │Monitor.│History │Compare │Dataset ││
│  │         │ Eval. │        │        │        │        ││
│  └────────┴────────┴────────┴────────┴────────┴────────┘│
│  ┌────────┬────────┬────────┬────────┐                  │
│  │Auto    │ Costs  │ Admin  │Logout  │                  │
│  │Improve │        │ (관리자)│        │                  │
│  └────────┴────────┴────────┴────────┘                  │
└─────────────────────────────────────────────────────────┘

[평가 워크플로우]
New Evaluation → Monitor → Results
                            │
                            └─→ Auto Improve (옵션)
                            └─→ Comparison (옵션)

[모니터링 워크플로우]
Monitoring → Monitor → Results

[이력 조회 워크플로우]
History → Results → Comparison (옵션)

[자동 개선 워크플로우]
Auto Improve Setup → Progress → Results → New Evaluation (재평가)

[비용 관리 워크플로우]
Costs → Budget Settings
      → Cost Alerts

[관리자 워크플로우]
Admin → Logs
      → User Management
      → System Configuration
```

### 3.3 페이지별 주요 기능 매트릭스

| 페이지 | 주요 기능 | 사용 권한 | 이동 가능 페이지 |
|--------|----------|----------|-----------------|
| **Dashboard** | 전체 현황, 최근 활동, Quick Actions | 모든 사용자 | 모든 페이지 |
| **New Evaluation** | 평가 설정 및 실행 | 모든 사용자 | Monitor |
| **Monitoring** | 진행 중인 평가 목록 | 모든 사용자 | Monitor |
| **Monitor** | 실시간 평가 진행 상황 | 모든 사용자 | Results |
| **History** | 과거 평가 목록 | 모든 사용자 | Results |
| **Results** | 평가 결과 상세 분석 | 모든 사용자 | Comparison, Auto Improve |
| **Comparison** | 여러 평가 비교 | 모든 사용자 | Results |
| **Datasets** | 데이터셋 CRUD | 모든 사용자 | New Evaluation |
| **Auto Improve** | 자동 개선 설정 | 모든 사용자 | Auto Improve Progress |
| **Auto Improve Progress** | 개선 실험 진행 | 모든 사용자 | Auto Improve Results |
| **Auto Improve Results** | 최적 설정 확인 | 모든 사용자 | New Evaluation |
| **Costs** | 비용 대시보드 | 모든 사용자 | Budget Settings, Cost Alerts |
| **Budget Settings** | 예산 관리 | 모든 사용자 | Costs |
| **Cost Alerts** | 비용 알림 | 모든 사용자 | Costs |
| **Admin** | 시스템 관리 | 관리자만 | Logs |
| **Logs** | 시스템 로그 | 관리자만 | Admin |

### 3.4 현재 구현된 페이지 목록 (V1.0)

```
✅ 완료된 페이지 (18개)
├─ 🔐 LoginPage.tsx
├─ 🏠 DashboardPageBlue.tsx
├─ ⚡ NewEvaluationPageBlue.tsx
├─ 📊 MonitoringPageBlue.tsx
├─ 🔄 EvaluationMonitorPageBlue.tsx
├─ 📜 EvaluationHistoryPageBlue.tsx
├─ 📈 ResultsPageBlue.tsx
├─ 🔍 ComparisonPageBlue.tsx
├─ 🗂️ DatasetsPageBlue.tsx
├─ ✨ AutoImproveSetupPageBlue.tsx
├─ ⏳ AutoImproveProgressPageBlue.tsx
├─ 🎯 AutoImproveResultsPageBlue.tsx
├─ 💰 CostDashboardPageBlue.tsx
├─ 💵 BudgetSettingsPageBlue.tsx
├─ 🔔 CostAlertsPageBlue.tsx
├─ 🛡️ AdminPageBlue.tsx
├─ 📋 LogViewerPageBlue.tsx
└─ 🎨 AppLayout.tsx (레이아웃)

📦 재사용 컴포넌트
├─ DiagnosisSummaryCard.tsx
├─ LLMJudgeAnalysisCard.tsx
└─ ui/ (40+ ShadCN 컴포넌트)

🔧 상태 관리
├─ evaluation-store.ts
└─ monitor-store.ts

🛠️ 유틸리티
├─ api-client.ts
├─ mock-data.ts
└─ score-analysis.ts
```

---

## 4. 시스템 아키텍처 도식화

### 2.1 전체 시스템 레이어

```
┌───────────────────────────────────────────────────────────────────┐
│                        사용자 인터페이스 레이어                    │
│  ┌─────────────────┐  ┌─────────────────┐  ┌──────────────────┐ │
│  │  일반 사용자     │  │   관리자        │  │  비용 관리       │ │
│  │  - 평가 실행     │  │  - 리소스 관리   │  │  - 비용 추적     │ │
│  │  - 결과 분석     │  │  - 사용자 계정   │  │  - 예산 설정     │ │
│  │  - 자동 개선     │  │  - LLM/VectorDB │  │  - 최적화 제안   │ │
│  └─────────────────┘  └─────────────────┘  └──────────────────┘ │
└───────────────────────────────────────────────────────────────────┘
                                 ▼
┌───────────────────────────────────────────────────────────────────┐
│                        비즈니스 로직 레이어                        │
│  ┌─────────────────┐  ┌─────────────────┐  ┌──────────────────┐ │
│  │  평가 엔진       │  │  자동 개선 엔진  │  │  비용 추적 엔진  │ │
│  │  - 지표 계산     │  │  - 원인 분석     │  │  - 토큰 카운팅   │ │
│  │  - 실시간 모니터링│  │  - 설정 생성     │  │  - 비용 계산     │ │
│  │  - 결과 저장     │  │  - 최적화 실험   │  │  - 예산 알림     │ │
│  └─────────────────┘  └─────────────────┘  └──────────────────┘ │
└───────────────────────────────────────────────────────────────────┘
                                 ▼
┌───────────────────────────────────────────────────────────────────┐
│                        데이터 & 연동 레이어                        │
│  ┌─────────────────┐  ┌─────────────────┐  ┌──────────────────┐ │
│  │  데이터베이스    │  │  외부 API       │  │  메시지 큐       │ │
│  │  - PostgreSQL    │  │  - OpenAI       │  │  - Redis/Celery  │ │
│  │  - 평가 결과     │  │  - Anthropic    │  │  - 비동기 작업   │ │
│  │  - 사용자 데이터 │  │  - VectorDB     │  │  - 작업 큐       │ │
│  └─────────────────┘  └─────────────────┘  └──────────────────┘ │
└───────────────────────────────────────────────────────────────────┘
```

### 2.2 기본 평가 워크플로우 (4단계)

```
[1] 데이터셋 준비
    │
    │  - 수동 생성 / CSV·JSON 업로드 / 자동 생성
    │  - 데이터 검증 (필수 필드, 형식 체크)
    │  - 메타데이터 태깅
    ▼
[2] 평가 환경 설정
    │
    │  - 12개 지표 중 선택
    │  - LLM Judge 모델 설정 (GPT-4o, Claude-3.5 등)
    │  - 샘플링 전략 구성 (휴리스틱 필터 + 고정 비율)
    │  - 비용 예측
    ▼
[3] 실시간 모니터링
    │
    │  - 진행률 (QA별, 지표별)
    │  - 실시간 점수 업데이트
    │  - 에러 발생 추적
    │  - 비용 누적 추적
    ▼
[4] 결과 분석
    │
    │  - 지표별 점수 분포 (히스토그램, 박스플롯)
    │  - 낮은 점수 케이스 분석
    │  - LLM Judge 근본 원인 분석 (샘플링된 케이스)
    │  - 개선 제안 자동 생성
    └──→ [자동 개선 워크플로우로 연결]
```

### 2.3 자동 개선 워크플로우 (3단계)

```
┌─────────────────────────────────────────────────────────────┐
│  Phase 1: 근본 원인 분석 (LLM Judge)                        │
├─────────────────────────────────────────────────────────────┤
│  입력: 낮은 점수 케이스 (샘플링된)                          │
│                                                              │
│  처리:                                                       │
│   1. 휴리스틱 1차 필터링 (Score Threshold, Context Check)   │
│   2. 고정 비율 샘플링 (30%)                                 │
│   3. LLM Judge 분석 (근본 원인 5-7가지 분류)                │
│                                                              │
│  출력: 원인별 집계 및 우선순위                               │
│   - 검색 실패 (35%)                                         │
│   - 청크 크기 부적절 (28%)                                  │
│   - 프롬프트 불명확 (22%)                                   │
│   - 컨텍스트 길이 부족 (15%)                                │
└─────────────────────────────────────────────────────────────┘
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 2: 개선안 생성 (Auto Config)                         │
├─────────────────────────────────────────────────────────────┤
│  입력: Phase 1의 원인 분석 결과                             │
│                                                              │
│  처리:                                                       │
│   - 원인별 설정 매핑 규칙 적용                              │
│   - 최적화된 설정 조합 3-5개 생성                           │
│                                                              │
│  출력: 개선안 목록                                           │
│   Config A: Chunk 512 → 256, Top-K 5 → 10                  │
│   Config B: Embedding ada-002 → text-embedding-3-large     │
│   Config C: Prompt Template 변경                            │
└─────────────────────────────────────────────────────────────┘
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 3: 최적 설정 탐색 (Optimization)                     │
├─────────────────────────────────────────────────────────────┤
│  입력: Phase 2의 개선안 목록                                │
│                                                              │
│  처리:                                                       │
│   - 그리드 서치 / 베이지안 최적화 / A/B 테스트              │
│   - 각 설정으로 실험 평가 실행 (N=12)                       │
│   - 성능 비교 (점수 개선률, 비용 효율성)                    │
│                                                              │
│  출력: 최적 설정 + 개선 리포트                              │
│   - Best Config: Config B                                   │
│   - 점수 개선: +18.5%                                       │
│   - 비용 변화: -12% (더 효율적)                             │
└─────────────────────────────────────────────────────────────┘
```

### 2.4 비용 최적화 전략

```
┌───────────────────────────────────────────────────────────┐
│            LLM Judge 호출 90% 이상 절감 전략              │
└───────────────────────────────────────────────────────────┘
                          │
            ┌─────────────┴─────────────┐
            ▼                            ▼
┌──────────────────────┐     ┌──────────────────────┐
│  1차 필터링 (휴리스틱) │     │  2차 필터링 (샘플링)  │
├──────────────────────┤     ├──────────────────────┤
│ ✓ Score Threshold     │     │ ✓ 고정 비율 30%      │
│   - 0.8 이상 제외     │     │ ✓ 계층화 샘플링      │
│                       │     │   (점수 구간별)      │
│ ✓ Context Volume      │     │                      │
│   - 너무 짧음 제외    │     │ ✓ 무작위 선택        │
│   - 너무 김 제외      │     │   (재현성 보장)      │
└──────────────────────┘     └──────────────────────┘
            │                            │
            └─────────────┬─────────────┘
                          ▼
            ┌──────────────────────────┐
            │  LLM Judge 호출 (10%)    │
            │  - 비용 90% 절감         │
            │  - 대표성 유지           │
            └──────────────────────────┘
```

### 2.5 12개 RAG 평가 지표 (실제 구현)

**TypeScript 타입 정의** (`/types/index.ts`):
```typescript
export type MetricName = 
  | 'faithfulness'              // 1
  | 'answer_relevancy'           // 2
  | 'context_precision'          // 3
  | 'context_recall'             // 4
  | 'answer_correctness'         // 5
  | 'context_entity_recall'      // 6
  | 'answer_similarity'          // 7
  | 'harmfulness'                // 8
  | 'maliciousness'              // 9
  | 'coherence'                  // 10
  | 'critique_correctness'       // 11
  | 'conciseness';               // 12
```

**카테고리별 분류**:

```
┌─────────────────────────────────────────────────────────────┐
│                   Generation 지표 (4개)                      │
├─────────────────────────────────────────────────────────────┤
│  1. faithfulness          - 답변이 컨텍스트에 충실한가?     │
│  2. answer_relevancy      - 답변이 질문과 관련 있는가?      │
│  5. answer_correctness    - 답변이 정답과 일치하는가?       │
│  7. answer_similarity     - 답변이 정답과 유사한가?         │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                    Retrieval 지표 (3개)                      │
├─────────────────────────────────────────────────────────────┤
│  3. context_precision     - 검색된 문서가 정확한가?         │
│  4. context_recall        - 필요한 문서를 모두 찾았는가?    │
│  6. context_entity_recall - 핵심 엔티티를 포함하는가?       │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                     Quality 지표 (3개)                       │
├─────────────────────────────────────────────────────────────┤
│  10. coherence            - 답변이 일관성 있는가?           │
│  11. critique_correctness - 비평/검토의 정확성              │
│  12. conciseness          - 답변이 간결한가?                │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                     Safety 지표 (2개)                        │
├─────────────────────────────────────────────────────────────┤
│  8. harmfulness           - 유해한 내용 검출                │
│  9. maliciousness         - 악의적인 내용 검출              │
└─────────────────────────────────────────────────────────────┘
```

**지표별 상세 설명**:

| # | 지표명 | 카테고리 | 설명 | LLM Judge 필요 |
|---|--------|---------|------|---------------|
| 1 | **faithfulness** | Generation | 생성된 답변이 검색된 컨텍스트에 충실하게 기반하고 있는지 평가 | ✅ |
| 2 | **answer_relevancy** | Generation | 답변이 원래 질문과 얼마나 관련이 있는지 평가 | ✅ |
| 3 | **context_precision** | Retrieval | 검색된 문서들이 질문에 대해 얼마나 정확한지 평가 | ✅ |
| 4 | **context_recall** | Retrieval | 필요한 모든 정보를 검색했는지 평가 (누락 여부) | ✅ |
| 5 | **answer_correctness** | Generation | 생성된 답변이 정답(Ground Truth)과 얼마나 일치하는지 평가 | ✅ |
| 6 | **context_entity_recall** | Retrieval | 검색된 컨텍스트가 핵심 엔티티를 포함하는지 평가 | ✅ |
| 7 | **answer_similarity** | Generation | 답변과 정답의 의미적 유사도 평가 | ✅ |
| 8 | **harmfulness** | Safety | 생성된 답변이 유해한 내용을 포함하는지 검출 | ✅ |
| 9 | **maliciousness** | Safety | 생성된 답변이 악의적인 의도를 포함하는지 검출 | ✅ |
| 10 | **coherence** | Quality | 답변의 논리적 일관성 및 구조 평가 | ✅ |
| 11 | **critique_correctness** | Quality | 답변에 대한 비평이나 검토의 정확성 평가 | ✅ |
| 12 | **conciseness** | Quality | 답변이 불필요한 내용 없이 간결한지 평가 | ✅ |

**참고**: 모든 지표는 LLM Judge를 활용하여 평가되며, V1.0에서는 샘플링 전략을 통해 비용을 90% 이상 절감합니다.

---

## 5. V1.0 구현 범위

### 3.1 프론트엔드 (100% 완료)

#### ✅ 완료된 페이지 및 기능

```
[일반 사용자 기능]
✅ 통합 대시보드 (DashboardPageBlue.tsx)
   - 전체 평가 현황, 최근 활동, 주요 지표 요약

✅ 데이터셋 관리 (DatasetsPageBlue.tsx)
   - 생성/업로드/편집/삭제
   - CSV/JSON 파싱, 자동 생성

✅ 평가 설정 (NewEvaluationPageBlue.tsx)
   - 12개 지표 선택
   - LLM Judge 설정
   - 샘플링 전략 설정
   - 비용 예측

✅ 실시간 모니터링 (EvaluationMonitorPageBlue.tsx)
   - 진행률 추적
   - 실시간 점수 업데이트
   - 에러 추적

✅ 평가 이력 (EvaluationHistoryPageBlue.tsx)
   - 과거 평가 목록
   - 필터링/검색

✅ 결과 분석 (ResultsPageBlue.tsx)
   - 점수 분포 시각화
   - 낮은 점수 케이스 분석
   - LLM Judge 근본 원인 분석

✅ 결과 비교 (ComparisonPageBlue.tsx)
   - 여러 평가 비교
   - 설정 차이 분석

✅ 자동 개선 (3개 페이지)
   - AutoImproveSetupPageBlue.tsx (설정)
   - AutoImproveProgressPageBlue.tsx (진행)
   - AutoImproveResultsPageBlue.tsx (결과)

[비용 관리 기능]
✅ 비용 대시보드 (CostDashboardPageBlue.tsx)
   - 총 비용, 제공사별/지표별 분석
   - 비용 추이 차트

✅ 예산 설정 (BudgetSettingsPageBlue.tsx)
   - 예산 한도 설정
   - 알림 임계값 설정

✅ 비용 알림 (CostAlertsPageBlue.tsx)
   - 예산 초과 알림
   - 비용 최적화 제안

[관리자 기능]
✅ 관리자 대시보드 (AdminPageBlue.tsx)
   - 시스템 리소스 모니터링
   - 사용자 계정 관리
   - LLM/VectorDB 관리

✅ 로그 뷰어 (LogViewerPageBlue.tsx)
   - 시스템 로그 검색/필터링
```

#### ✅ 주요 컴포넌트

```
[UI 컴포넌트 (ShadCN)]
✅ 40+ 재사용 가능한 UI 컴포넌트
   - Button, Card, Dialog, Table, Chart 등

[분석 컴포넌트]
✅ DiagnosisSummaryCard.tsx
   - 근본 원인 분석 결과 표시

✅ LLMJudgeAnalysisCard.tsx
   - LLM Judge 분석 결과 상세 표시
```

#### ✅ 상태 관리

```
✅ evaluation-store.ts
   - 평가 상태 전역 관리

✅ monitor-store.ts
   - 모니터링 상태 관리
```

#### ✅ 유틸리티

```
✅ score-analysis.ts
   - 점수 분석 알고리즘
   - 낮은 점수 케이스 탐지

✅ api-client.ts
   - 백엔드 API 연동 준비

✅ mock-data.ts
   - 개발/데모용 Mock 데이터
```

### 3.2 백엔드 (V1.0 범위)

#### 🔧 구현 예정 (2025-11-30까지)

```
[API 서버]
🔧 FastAPI/Django 기반
   - RESTful API 엔드포인트
   - WebSocket (실시간 모니터링)
   - JWT 인증

[평가 엔진]
🔧 Celery + Redis
   - 비동기 평가 작업 큐
   - 12개 지표 계산 로직
   - LLM Judge 호출 (샘플링 적용)

[데이터베이스]
🔧 PostgreSQL
   - 사용자, 데이터셋, 평가 결과 저장
   - 인덱싱 최적화

[외부 API 연동]
🔧 OpenAI, Anthropic, Google AI
   - API 키 관리
   - 토큰 사용량 추적
   - 비용 계산

[비용 추적]
🔧 실시간 토큰 카운팅
   - tiktoken 라이브러리 사용
   - 제공사별 가격표 정기 업데이트
   - 예산 알림 자동화
```

### 3.3 V1.0 핵심 기능 요약 (조정안)

| 영역         | 기능                  | V1.0 상태  | 비고                           |
| ------------ | --------------------- | ---------- | ------------------------------ |
| **평가**     | 12개 지표 계산        | 🎯 핵심    | 백엔드 구현 필수               |
| **평가**     | 실시간 모니터링       | 🎯 핵심    | WebSocket + Redis              |
| **평가**     | 결과 분석             | 🎯 핵심    | 점수 분포, 케이스 분석         |
| **평가**     | 결과 비교             | 🎯 핵심    | 여러 평가 비교 기능            |
| **자동개선** | Phase 1 (원인 분석)   | ⏳ V2.0    | **V2.0 이관** (프론트 유지)    |
| **자동개선** | Phase 2 (개선안 생성) | ⏳ V2.0    | **V2.0 이관** (프론트 유지)    |
| **자동개선** | Phase 3 (최적화)      | ⏳ V2.0    | **V2.0 이관** (프론트 유지)    |
| **비용**     | 실시간 추적           | 🎯 핵심    | 토큰 카운팅, 비용 계산         |
| **비용**     | 예산 관리             | 🎯 핵심    | Hard Limit, 알림               |
| **비용**     | 샘플링 전략           | 🎯 핵심    | 휴리스틱 + 30% 샘플링 (90% 절감) |
| **관리**     | 사용자 관리           | 🎯 핵심    | JWT 인증, 기본 RBAC            |
| **관리**     | 시스템 모니터링       | 🎯 핵심    | 리소스 추적, 로그 조회         |

**범례**:
- 🎯 핵심: V1.0 필수 구현
- ⏳ V2.0: 차기 버전 이관
- ✅ 완료: 프론트엔드 완료

**중요**: 자동 개선 기능은 프론트엔드가 완성되어 있으나, 백엔드 구현은 V2.0으로 이관합니다.

### 3.4 V1.0 제외 사항 (V2.0 이관)

```
❌ V1.0에서 백엔드 구현 제외 → V2.0 이관
   
   [자동 개선 전체 (최우선 이관)]
   - Phase 1: 근본 원인 분석 (LLM Judge 기반)
   - Phase 2: 개선안 생성 (설정 조합 생성)
   - Phase 3: 최적 설정 탐색 (그리드 서치/베이지안 최적화)
   ⚠️ 프론트엔드는 완성되어 있으나 비활성화 또는 "Coming Soon" 표시
   
   [고급 기능]
   - 베이지안 최적화 알고리즘
   - 멀티 테넌트 격리
   - 고급 RBAC (세밀한 권한 관리)
   - 커스텀 지표 생성 UI
   - 반복 평가 스케줄링 (Cron)
   - 알림 채널 확장 (Slack, Email, Webhook)
   - API 레이트 리미팅 고도화
```

### 3.5 프론트엔드 자동 개선 페이지 처리 방안

자동 개선 관련 프론트엔드는 이미 완성되어 있으므로, 다음과 같이 처리합니다:

**Option 1: 비활성화 + 안내 메시지 (권장)**
```tsx
// AutoImproveSetupPageBlue.tsx 상단에 Alert 추가
<Alert className="border-blue-200 bg-blue-50">
  <Info className="h-4 w-4 text-blue-600" />
  <AlertTitle className="text-blue-900">Coming Soon - V2.0</AlertTitle>
  <AlertDescription className="text-blue-800 text-sm">
    자동 개선 기능은 V2.0에서 출시될 예정입니다. 
    현재는 평가 결과의 "낮은 점수 케이스" 분석을 통해 수동으로 개선 방향을 확인하실 수 있습니다.
  </AlertDescription>
</Alert>
```

**Option 2: 메뉴에서 숨김 처리**
```tsx
// AppLayout.tsx에서 조건부 렌더링
const navigationItems = [
  { id: 'dashboard', label: '통합 대시보드', icon: Home },
  // ...
  // { id: 'auto-improve', label: '자동 개선', icon: Sparkles }, // V1.0 숨김
];
```

**Option 3: 데모 모드로 표시 (Mock 데이터)**
- 현재 Mock 데이터로 동작하는 것을 "데모 버전"으로 표시
- 실제 API 연동은 V2.0에서 활성화

---

## 6. V2.0 이후 로드맵

### 6.1 V2.0 핵심: 자동 개선 기능 완성 (2026-Q1)

**V1.0의 안정적인 평가 데이터를 기반으로 구축**

```
🎯 자동 개선 Phase 1: 근본 원인 분석
   - 낮은 점수 케이스의 LLM Judge 분석
   - 샘플링된 케이스 기반 원인 분류
   - 원인별 집계 및 우선순위 산정
   - 프론트엔드: 이미 완성 (V1.0에서 비활성화 상태)

🎯 자동 개선 Phase 2: 개선안 생성
   - 원인별 설정 매핑 규칙 엔진
   - 3-5개 최적화 설정 조합 생성
   - 예상 성능 개선률 계산
   - 프론트엔드: 이미 완성 (V1.0에서 비활성화 상태)

🎯 자동 개선 Phase 3: 최적 설정 탐색
   - 그리드 서치 구현
   - 각 설정으로 실험 평가 자동 실행
   - 성능 비교 (점수, 비용 효율성)
   - 최적 설정 자동 선정 및 적용 제안
   - 프론트엔드: 이미 완성 (V1.0에서 비활성화 상태)
```

### 6.2 Phase 3 고도화 (V2.5)

```
🚀 베이지안 최적화
   - 효율적인 하이퍼파라미터 탐색
   - 실험 횟수 50% 감소

🚀 강화학습 기반 자동 튜닝
   - 지속적인 성능 개선
   - 도메인별 최적화
```

### 6.3 고급 기능 (V2.5)

```
🔮 커스텀 지표 생성
   - 도메인 특화 지표 정의
   - Python 코드 업로드

🔮 반복 평가 스케줄링
   - Cron 기반 자동 평가
   - 성능 변화 추적

🔮 알림 채널 확장
   - Slack, Email, Webhook
   - 커스터마이징 가능한 알림 규칙
```

### 6.4 엔터프라이즈 기능 (V3.0)

```
🏢 멀티 테넌트 격리
   - 조직별 데이터 분리
   - 리소스 할당 제어

🏢 고급 RBAC
   - 세밀한 권한 관리
   - 감사 로그

🏢 SSO/SAML 연동
   - 엔터프라이즈 인증 통합
```

---

## 7. V1.0 vs V2.0 비교표

### 7.1 기능 비교

| 기능 영역 | V1.0 (2025-11-30) | V2.0 (2026-Q1) |
|----------|------------------|----------------|
| **평가 엔진** | ✅ 12개 지표 계산<br>✅ 실시간 모니터링<br>✅ 결과 분석 | ✅ 유지 + 안정화 |
| **비용 최적화** | ✅ 샘플링 전략 (90% 절감)<br>✅ 실시간 추적<br>✅ 예산 관리 | ✅ 유지 + 최적화 |
| **자동 개선** | ❌ 백엔드 미구현<br>⚠️ 프론트엔드만 완성<br>(비활성화 또는 데모) | ✅ Phase 1, 2, 3<br>완전 구현 |
| **관리자** | ✅ 기본 기능<br>✅ 로그 조회 | ✅ 유지 |
| **인증/보안** | ✅ JWT 기본 인증 | ✅ 고급 RBAC |

### 7.2 개발 리스크 비교

| 항목 | V1.0 집중 전략 | V1.0 + 자동개선 동시 진행 |
|------|--------------|------------------------|
| **일정 준수 가능성** | 🟢 높음 (80%) | 🔴 낮음 (30%) |
| **품질 보장** | 🟢 높음 | 🔴 낮음 (시간 부족) |
| **기술 부채** | 🟢 낮음 | 🔴 높음 (급하게 구현) |
| **유지보수성** | 🟢 높음 | 🟠 중간 |
| **베타 테스트 시간** | 🟢 충분 (1주) | 🔴 부족 (1-2일) |

### 7.3 권장 전략

```
✅ V1.0 MVP 전략 (권장)
   
   [집중 항목]
   1. 12개 RAG 지표 안정적 측정
   2. LLM Judge API 연동 (샘플링 적용)
   3. 실시간 모니터링 (WebSocket)
   4. 비용 추적 및 예산 관리
   5. 기본 인증 및 사용자 관리
   
   [품질 목표]
   - 시스템 안정성: 99% 이상
   - 평가 정확도: 95% 이상
   - 비용 절감: 90% 이상
   - API 응답 시간: P95 < 2초
   
   [자동 개선 처리]
   - 프론트엔드: 완성 상태 유지 (비활성화)
   - 백엔드: V2.0에서 집중 개발
   - 사용자: "Coming Soon - V2.0" 안내
   
   [이점]
   1. 핵심 기능의 안정성 확보
   2. 충분한 테스트 시간 확보
   3. 기술 부채 최소화
   4. V2.0 개발 시 안정적인 기반
```

---

## 8. 기술 스택 요약

### 8.1 프론트엔드

```yaml
프레임워크:
  - React 18
  - TypeScript
  - Tailwind CSS v4

상태 관리:
  - Zustand

UI 라이브러리:
  - ShadCN UI (40+ 컴포넌트)
  - Lucide Icons
  - Recharts (차트)

빌드 도구:
  - Vite
```

### 8.2 백엔드 (계획)

```yaml
API 서버:
  - FastAPI / Django
  - RESTful + WebSocket

작업 큐:
  - Celery
  - Redis

데이터베이스:
  - PostgreSQL

외부 API:
  - OpenAI API
  - Anthropic API
  - Google AI API
  - VectorDB 연동 (Pinecone, Weaviate 등)
```

### 8.3 인프라 (계획)

```yaml
배포:
  - Docker + Kubernetes
  - CI/CD (GitHub Actions)

모니터링:
  - Prometheus + Grafana
  - Sentry (에러 추적)

보안:
  - JWT 인증
  - API 키 암호화 (Vault)
  - HTTPS 강제
```

---

## 9. 핵심 성과 지표 (KPI)

### 9.1 V1.0 출시 시 달성 목표

| KPI                  | 목표       | 측정 방법                       |
| -------------------- | ---------- | ------------------------------- |
| **비용 절감률**      | 90% 이상   | LLM Judge 호출 횟수 비교        |
| **평가 정확도**      | 95% 이상   | 샘플링 vs 전수 평가 점수 일치도 |
| **시스템 응답 시간** | < 2초      | API 응답 시간 (P95)             |
| **평가 처리량**      | 1000 QA/분 | 동시 평가 처리 능력             |
| **사용자 만족도**    | 4.5/5.0    | 베타 테스터 설문                |

### 9.2 비용 절감 시뮬레이션

```
[시나리오: 1000 QA 평가]

Without Sampling (전수 평가):
  - LLM Judge 호출: 1000회
  - 평균 토큰: 800 tokens/call
  - 총 토큰: 800,000 tokens
  - 비용 (GPT-4o): ~$4.80

With Sampling (휴리스틱 + 30%):
  - 1차 필터링: 600 케이스 제외 (Score > 0.8)
  - 2차 샘플링: 120 케이스 선택 (400 × 30%)
  - LLM Judge 호출: 120회
  - 총 토큰: 96,000 tokens
  - 비용 (GPT-4o): ~$0.58

💰 절감률: 87.9%
✅ 대표성: 점수 분포 오차 < 5%
```

---

## 10. 위험 요소 및 대응 방안

### 10.1 주요 위험 요소

| 위험             | 영향도 | 확률 | 대응 방안                    |
| ---------------- | ------ | ---- | ---------------------------- |
| **LLM API 장애** | 높음   | 중간 | 재시도 로직, Fallback 모델   |
| **비용 폭증**    | 높음   | 낮음 | 예산 Hard Limit, 실시간 알림 |
| **성능 병목**    | 중간   | 중간 | 비동기 처리, 캐싱, CDN       |
| **데이터 유실**  | 높음   | 낮음 | 정기 백업, 복제              |
| **보안 침해**    | 높음   | 낮음 | API 키 암호화, 권한 관리     |

### 10.2 대응 전략

```
✓ API 장애 대응
  - 3회 재시도 (Exponential Backoff)
  - Fallback 모델 자동 전환
  - 부분 실패 허용 (Graceful Degradation)

✓ 비용 통제
  - 예산 Hard Limit 설정
  - 임계값 80% 시 알림
  - 사용자별 Quota 관리

✓ 성능 최적화
  - Redis 캐싱 (평가 결과, 토큰 카운트)
  - DB 인덱싱 최적화
  - Lazy Loading

✓ 보안 강화
  - API 키 Vault 저장
  - JWT 토큰 만료 관리
  - HTTPS 강제
  - 입력 데이터 Sanitization
```

---

## 10. 일정 계획 (현실적 조정안)

### 10.1 V1.0 MVP 마일스톤 (2025-11-30)

**핵심 목표**: 안정적인 RAG 평가 시스템 + 비용 최적화 구축

```
Week 1-2 (2025-10-17 ~ 2025-10-30):
  ✅ 프론트엔드 100% 완료
  🎯 백엔드 기본 아키텍처 구축
     - FastAPI/Django 프로젝트 설정
     - PostgreSQL 스키마 설계 및 마이그레이션
     - Celery + Redis 비동기 작업 큐 구성
     - JWT 인증 구현

Week 3-4 (2025-10-31 ~ 2025-11-13):
  🎯 평가 엔진 핵심 구현
     - 12개 RAG 지표 계산 로직
     - LLM Judge API 연동 (OpenAI, Anthropic)
     - 샘플링 전략 구현 (휴리스틱 + 30%)
     - RAG 시스템 연동 (VectorDB)

Week 5 (2025-11-14 ~ 2025-11-20):
  🎯 비용 추적 및 모니터링
     - 토큰 카운팅 (tiktoken)
     - 실시간 비용 계산
     - 예산 관리 및 알림
     - WebSocket 실시간 모니터링

Week 6 (2025-11-21 ~ 2025-11-27):
  🎯 통합 테스트 및 최적화
     - API 통합 테스트
     - 성능 병목 해결
     - Redis 캐싱 최적화
     - 에러 처리 강화

Week 7 (2025-11-28 ~ 2025-11-30):
  🎯 베타 테스트 및 출시 준비
     - 사용자 베타 테스트
     - 버그 수정
     - 문서 작성
     ✅ V1.0 MVP 출시

❌ V1.0에서 제외 (V2.0으로 이관):
   - 자동 개선 Phase 1, 2, 3 백엔드 구현
   - 고급 최적화 알고리즘
```

### 10.2 V2.0 로드맵 (2026-Q1)

**V1.0 출시 직후 시작**

```
Month 1 (2025-12):
  🚀 자동 개선 Phase 1 구현
     - LLM Judge 근본 원인 분석 백엔드
     - 원인별 집계 및 우선순위 로직
     - 안정적인 V1.0 평가 데이터 기반

Month 2 (2026-01):
  🚀 자동 개선 Phase 2 구현
     - 원인별 설정 매핑 규칙
     - 개선안 생성 알고리즘
     - 설정 조합 생성 로직

Month 3 (2026-02):
  🚀 자동 개선 Phase 3 구현
     - 그리드 서치 구현
     - 베이지안 최적화 (선택)
     - 성능 비교 및 최적 설정 선정
     
  ✅ V2.0 출시 (2026-Q1 말)
```

---

## 11. 문서 버전 이력

| 버전 | 날짜       | 작성자 | 변경 사항 |
| ---- | ---------- | ------ | --------- |
| 1.0  | 2025-10-16 | 박찬식 | 초안 작성 |

---

## 12. 참고 문서

- [Architecture-Overview.md](./Architecture-Overview.md) - 전체 아키텍처 상세
- [V1.0-Production-Readiness-Guide.md](./V1.0-Production-Readiness-Guide.md) - 프로덕션 준비
- [V1.0-LLM-Judge-Cost-Reduction-COMPLETE.md](./V1.0-LLM-Judge-Cost-Reduction-COMPLETE.md) - 비용 절감 전략
- [Auto-Improve-Algorithm-Specification.md](./Auto-Improve-Algorithm-Specification.md) - 자동 개선 알고리즘

---

**문서 끝**