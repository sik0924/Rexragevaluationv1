# Auto-Improve êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [Level 1 êµ¬í˜„ ì˜ˆì‹œ (ê¶Œì¥)](#level-1-êµ¬í˜„-ì˜ˆì‹œ-ê¶Œì¥)
2. [ë°±ì—”ë“œ êµ¬í˜„ (Python FastAPI)](#ë°±ì—”ë“œ-êµ¬í˜„-python-fastapi)
3. [í”„ë¡ íŠ¸ì—”ë“œ í†µí•©](#í”„ë¡ íŠ¸ì—”ë“œ-í†µí•©)
4. [í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤](#í…ŒìŠ¤íŠ¸-ì‹œë‚˜ë¦¬ì˜¤)

---

## Level 1 êµ¬í˜„ ì˜ˆì‹œ (ê¶Œì¥)

### 1ë‹¨ê³„: ê·¼ë³¸ ì›ì¸ ë¶„ì„ (Root Cause Analysis)

#### ë°±ì—”ë“œ ë¡œì§ (Python)

```python
from typing import Dict, List, Literal
from dataclasses import dataclass

@dataclass
class RootCauseAnalysis:
    retrieval: Dict | None
    generation: Dict | None
    recommended_strategy: Literal['retrieval_first', 'generation_first', 'balanced']
    estimated_experiments: int
    estimated_cost: float
    estimated_duration_minutes: int

def analyze_root_cause(evaluation_result: dict) -> RootCauseAnalysis:
    """
    í‰ê°€ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í•˜ê³  ìµœì í™” ì „ëµì„ ì œì•ˆ
    """
    scores = evaluation_result['scores']
    
    # 1. Retrieval ì§€í‘œ ë¶„ì„
    retrieval_metrics = {
        'context_precision': scores.get('context_precision', 0),
        'context_recall': scores.get('context_recall', 0),
        'context_entity_recall': scores.get('context_entity_recall', 0)
    }
    retrieval_avg = sum(retrieval_metrics.values()) / len(retrieval_metrics)
    
    # 2. Generation ì§€í‘œ ë¶„ì„
    generation_metrics = {
        'faithfulness': scores.get('faithfulness', 0),
        'answer_relevancy': scores.get('answer_relevancy', 0),
        'answer_correctness': scores.get('answer_correctness', 0),
        'coherence': scores.get('coherence', 0),
        'conciseness': scores.get('conciseness', 0)
    }
    generation_avg = sum(generation_metrics.values()) / len(generation_metrics)
    
    # 3. Severity ê²°ì •
    def get_severity(avg_score: float) -> str:
        if avg_score < 0.6:
            return 'high'
        elif avg_score < 0.75:
            return 'medium'
        else:
            return 'low'
    
    retrieval_severity = get_severity(retrieval_avg)
    generation_severity = get_severity(generation_avg)
    
    # 4. ìš°ì„ ìˆœìœ„ íŒŒë¼ë¯¸í„° ê²°ì •
    retrieval_priority_params = []
    if retrieval_metrics['context_recall'] < 0.7:
        retrieval_priority_params.extend(['top_k', 'embedding_model'])
    if retrieval_metrics['context_precision'] < 0.7:
        retrieval_priority_params.extend(['chunk_size', 'top_k'])
    
    generation_priority_params = []
    if generation_metrics['faithfulness'] < 0.7:
        generation_priority_params.extend(['temperature', 'llm_model'])
    if generation_metrics['answer_correctness'] < 0.7:
        generation_priority_params.extend(['llm_model', 'max_tokens'])
    
    # 5. ì „ëµ ê²°ì •
    if retrieval_severity == 'high' and generation_severity != 'high':
        strategy = 'retrieval_first'
        estimated_experiments = 8
    elif generation_severity == 'high' and retrieval_severity != 'high':
        strategy = 'generation_first'
        estimated_experiments = 10
    else:
        strategy = 'balanced'
        estimated_experiments = 12
    
    # 6. ë¹„ìš© ë° ì‹œê°„ ì¶”ì •
    cost_per_experiment = 1.5  # $1.5 per evaluation (150 QA pairs)
    time_per_experiment = 15   # 15 minutes per evaluation
    
    return RootCauseAnalysis(
        retrieval={
            'severity': retrieval_severity,
            'affected_metrics': [
                k for k, v in retrieval_metrics.items() if v < 0.7
            ],
            'scores': retrieval_metrics,
            'priority_params': list(set(retrieval_priority_params))
        } if retrieval_severity != 'low' else None,
        generation={
            'severity': generation_severity,
            'affected_metrics': [
                k for k, v in generation_metrics.items() if v < 0.7
            ],
            'scores': generation_metrics,
            'priority_params': list(set(generation_priority_params))
        } if generation_severity != 'low' else None,
        recommended_strategy=strategy,
        estimated_experiments=estimated_experiments,
        estimated_cost=estimated_experiments * cost_per_experiment,
        estimated_duration_minutes=estimated_experiments * time_per_experiment
    )
```

#### FastAPI ì—”ë“œí¬ì¸íŠ¸

```python
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

router = APIRouter(prefix="/api/v1/auto-improve", tags=["auto-improve"])

class AnalyzeRequest(BaseModel):
    evaluation_id: str
    target_metrics: list[str] | None = None

@router.post("/analyze")
async def analyze_root_cause_endpoint(request: AnalyzeRequest):
    """
    ê·¼ë³¸ ì›ì¸ ë¶„ì„ API
    """
    # 1. í‰ê°€ ê²°ê³¼ ì¡°íšŒ
    evaluation = await get_evaluation_by_id(request.evaluation_id)
    
    if not evaluation:
        raise HTTPException(status_code=404, detail="Evaluation not found")
    
    if evaluation['status'] != 'completed':
        raise HTTPException(
            status_code=400, 
            detail="Evaluation must be completed"
        )
    
    # 2. ê·¼ë³¸ ì›ì¸ ë¶„ì„ ìˆ˜í–‰
    analysis = analyze_root_cause(evaluation)
    
    # 3. ê²°ê³¼ ë°˜í™˜
    return {
        "success": True,
        "data": {
            "root_causes": {
                "retrieval": analysis.retrieval,
                "generation": analysis.generation
            },
            "recommended_strategy": analysis.recommended_strategy,
            "estimated_experiments": analysis.estimated_experiments,
            "estimated_cost": analysis.estimated_cost,
            "estimated_duration_minutes": analysis.estimated_duration_minutes
        }
    }
```

---

### 2ë‹¨ê³„: ì‹¤í—˜ ì¡°í•© ìƒì„± (Smart Grid Search)

#### ë°±ì—”ë“œ ë¡œì§

```python
from typing import List, Dict
from itertools import product

def generate_retrieval_first_experiments(
    baseline_config: dict,
    priority_params: List[str]
) -> List[Dict]:
    """
    Retrieval ìš°ì„  ìµœì í™” ì „ëµ
    """
    experiments = []
    current_config = baseline_config.copy()
    
    # Phase 1: Top-K ìµœì í™” (3-4íšŒ)
    if 'top_k' in priority_params:
        for top_k in [3, 5, 10, 15]:
            exp_config = current_config.copy()
            exp_config['top_k'] = top_k
            experiments.append({
                'name': f'Top-K={top_k}',
                'config': exp_config,
                'phase': 'retrieval_top_k'
            })
        
        # ìµœê³  ì„±ëŠ¥ Top-K ê°’ ê²°ì • (ì‹œë®¬ë ˆì´ì…˜)
        # ì‹¤ì œë¡œëŠ” í‰ê°€ í›„ ê²°ì •
        current_config['top_k'] = 5
    
    # Phase 2: Chunk Size ìµœì í™” (3-4íšŒ)
    if 'chunk_size' in priority_params:
        for chunk_size in [128, 256, 512, 1024]:
            if chunk_size == baseline_config.get('chunk_size'):
                continue
            exp_config = current_config.copy()
            exp_config['chunk_size'] = chunk_size
            experiments.append({
                'name': f'ChunkSize={chunk_size}',
                'config': exp_config,
                'phase': 'retrieval_chunk_size'
            })
        
        current_config['chunk_size'] = 512
    
    # Phase 3: Embedding Model ë³€ê²½ (2-3íšŒ)
    if 'embedding_model' in priority_params:
        for model in ['text-embedding-3-small', 'text-embedding-3-large']:
            if model == baseline_config.get('embedding_model'):
                continue
            exp_config = current_config.copy()
            exp_config['embedding_model'] = model
            experiments.append({
                'name': f'Embedding={model}',
                'config': exp_config,
                'phase': 'retrieval_embedding'
            })
    
    return experiments[:12]  # ìµœëŒ€ 12ê°œ ì‹¤í—˜

def generate_generation_first_experiments(
    baseline_config: dict,
    priority_params: List[str]
) -> List[Dict]:
    """
    Generation ìš°ì„  ìµœì í™” ì „ëµ
    """
    experiments = []
    current_config = baseline_config.copy()
    
    # Phase 1: Temperature ìµœì í™” (4-5íšŒ)
    if 'temperature' in priority_params:
        for temp in [0.1, 0.3, 0.5, 0.7, 0.9]:
            exp_config = current_config.copy()
            exp_config['temperature'] = temp
            experiments.append({
                'name': f'Temperature={temp}',
                'config': exp_config,
                'phase': 'generation_temperature'
            })
        
        current_config['temperature'] = 0.3
    
    # Phase 2: LLM Model ë³€ê²½ (3-4íšŒ)
    if 'llm_model' in priority_params:
        for model in ['GPT-4o', 'GPT-4o-mini', 'Claude-3.5 Sonnet', 'Claude-3 Opus']:
            if model == baseline_config.get('llm_model'):
                continue
            exp_config = current_config.copy()
            exp_config['llm_model'] = model
            experiments.append({
                'name': f'LLM={model}',
                'config': exp_config,
                'phase': 'generation_llm'
            })
        
        current_config['llm_model'] = 'Claude-3.5 Sonnet'
    
    # Phase 3: Max Tokens ì¡°ì • (3-4íšŒ)
    if 'max_tokens' in priority_params:
        for tokens in [128, 256, 512, 1024]:
            if tokens == baseline_config.get('max_tokens'):
                continue
            exp_config = current_config.copy()
            exp_config['max_tokens'] = tokens
            experiments.append({
                'name': f'MaxTokens={tokens}',
                'config': exp_config,
                'phase': 'generation_max_tokens'
            })
    
    return experiments[:12]

def generate_balanced_experiments(
    baseline_config: dict,
    retrieval_params: List[str],
    generation_params: List[str]
) -> List[Dict]:
    """
    ê· í˜• ì¡íŒ ìµœì í™” ì „ëµ
    """
    experiments = []
    
    # Retrieval (6íšŒ)
    ret_exp = generate_retrieval_first_experiments(baseline_config, retrieval_params)
    experiments.extend(ret_exp[:6])
    
    # Generation (6íšŒ)
    gen_exp = generate_generation_first_experiments(baseline_config, generation_params)
    experiments.extend(gen_exp[:6])
    
    return experiments[:12]
```

#### FastAPI ì—”ë“œí¬ì¸íŠ¸

```python
class GenerateExperimentsRequest(BaseModel):
    base_evaluation_id: str
    strategy: Literal['retrieval_first', 'generation_first', 'balanced']
    optimization_level: Literal['rule_based'] = 'rule_based'
    budget: dict | None = None

@router.post("/generate-experiments")
async def generate_experiments_endpoint(request: GenerateExperimentsRequest):
    """
    ì‹¤í—˜ ì¡°í•© ìƒì„± API
    """
    # 1. ê¸°ì¤€ í‰ê°€ ì¡°íšŒ
    baseline_eval = await get_evaluation_by_id(request.base_evaluation_id)
    
    if not baseline_eval:
        raise HTTPException(status_code=404, detail="Baseline evaluation not found")
    
    # 2. ê·¼ë³¸ ì›ì¸ ë¶„ì„
    analysis = analyze_root_cause(baseline_eval)
    
    # 3. ì „ëµì— ë”°ë¼ ì‹¤í—˜ ìƒì„±
    if request.strategy == 'retrieval_first':
        retrieval_params = analysis.retrieval['priority_params'] if analysis.retrieval else []
        experiments = generate_retrieval_first_experiments(
            baseline_eval['config'],
            retrieval_params
        )
    elif request.strategy == 'generation_first':
        generation_params = analysis.generation['priority_params'] if analysis.generation else []
        experiments = generate_generation_first_experiments(
            baseline_eval['config'],
            generation_params
        )
    else:  # balanced
        retrieval_params = analysis.retrieval['priority_params'] if analysis.retrieval else []
        generation_params = analysis.generation['priority_params'] if analysis.generation else []
        experiments = generate_balanced_experiments(
            baseline_eval['config'],
            retrieval_params,
            generation_params
        )
    
    # 4. ì˜ˆì‚° ì œì•½ ì ìš©
    if request.budget:
        max_exp = request.budget.get('max_experiments')
        if max_exp and len(experiments) > max_exp:
            experiments = experiments[:max_exp]
    
    # 5. Job ID ìƒì„±
    job_id = f"auto-improve-job-{uuid.uuid4()}"
    
    # 6. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    await save_auto_improve_job({
        'job_id': job_id,
        'base_evaluation_id': request.base_evaluation_id,
        'strategy': request.strategy,
        'experiments': experiments,
        'status': 'pending'
    })
    
    return {
        "success": True,
        "data": {
            "job_id": job_id,
            "experiments": [
                {
                    "id": f"exp-{i+1}",
                    "name": exp['name'],
                    "config": exp['config'],
                    "order": i + 1
                }
                for i, exp in enumerate(experiments)
            ],
            "total_experiments": len(experiments),
            "estimated_cost": len(experiments) * 1.5,
            "estimated_duration_minutes": len(experiments) * 15
        }
    }
```

---

### 3ë‹¨ê³„: í‰ê°€ ì‹¤í–‰ ë° Early Stopping

#### Celery íƒœìŠ¤í¬ (ë¹„ë™ê¸° í‰ê°€)

```python
from celery import Celery, Task
import redis

celery_app = Celery('rex', broker='redis://localhost:6379/0')
redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)

class EarlyStoppingChecker:
    def __init__(self, config: dict):
        self.min_improvement = config.get('min_improvement', 0.05)
        self.patience = config.get('patience', 3)
        self.target_score = config.get('target_score', 0.9)
        self.no_improvement_count = 0
        self.best_score = 0.0
    
    def should_stop(self, current_score: float) -> tuple[bool, str]:
        """
        ì¡°ê¸° ì¢…ë£Œ ì—¬ë¶€ íŒë‹¨
        Returns: (should_stop, reason)
        """
        # ëª©í‘œ ì ìˆ˜ ë‹¬ì„±
        if current_score >= self.target_score:
            return True, f"ëª©í‘œ ì ìˆ˜ {self.target_score} ë‹¬ì„±!"
        
        # ê°œì„  í™•ì¸
        improvement = (current_score - self.best_score) / self.best_score if self.best_score > 0 else 0
        
        if improvement >= self.min_improvement:
            # ê°œì„ ë¨
            self.best_score = current_score
            self.no_improvement_count = 0
            return False, ""
        else:
            # ê°œì„  ì—†ìŒ
            self.no_improvement_count += 1
            
            if self.no_improvement_count >= self.patience:
                return True, f"{self.patience}íšŒ ì—°ì† ê°œì„  ì—†ìŒ"
        
        return False, ""

@celery_app.task(bind=True)
def run_auto_improve_job(self: Task, job_id: str, config: dict):
    """
    ìë™ ê°œì„  ì‘ì—… ì‹¤í–‰ (Celery Task)
    """
    job = get_auto_improve_job(job_id)
    experiments = job['experiments']
    baseline_score = job['baseline_score']
    
    early_stopping = EarlyStoppingChecker(config.get('early_stopping', {}))
    completed_experiments = []
    best_config = None
    best_score = baseline_score
    
    for i, experiment in enumerate(experiments):
        # ì§„í–‰ ìƒí™© ë°œí–‰ (Redis Pub/Sub)
        redis_client.publish(
            f"auto-improve-{job_id}",
            json.dumps({
                'type': 'experiment_start',
                'experiment_id': experiment['id'],
                'experiment_name': experiment['name'],
                'progress': int((i / len(experiments)) * 100)
            })
        )
        
        # í‰ê°€ ì‹¤í–‰
        try:
            eval_result = run_evaluation(experiment['config'])
            current_score = eval_result['avg_score']
            
            experiment_result = {
                **experiment,
                'score': current_score,
                'scores': eval_result['scores'],
                'status': 'completed'
            }
            completed_experiments.append(experiment_result)
            
            # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
            if current_score > best_score:
                best_score = current_score
                best_config = experiment['config']
            
            # Early Stopping ì²´í¬
            should_stop, reason = early_stopping.should_stop(current_score)
            
            if should_stop:
                redis_client.publish(
                    f"auto-improve-{job_id}",
                    json.dumps({
                        'type': 'early_stopping',
                        'reason': reason,
                        'experiments_completed': i + 1
                    })
                )
                break
        
        except Exception as e:
            # ì‹¤í—˜ ì‹¤íŒ¨
            experiment_result = {
                **experiment,
                'status': 'failed',
                'error': str(e)
            }
            completed_experiments.append(experiment_result)
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    final_result = {
        'job_id': job_id,
        'status': 'completed',
        'experiments_completed': len(completed_experiments),
        'best_config': best_config,
        'improvement': {
            'baseline_score': baseline_score,
            'best_score': best_score,
            'improvement_rate': (best_score - baseline_score) / baseline_score
        },
        'detailed_results': completed_experiments
    }
    
    save_auto_improve_result(job_id, final_result)
    
    # ì™„ë£Œ ì•Œë¦¼
    redis_client.publish(
        f"auto-improve-{job_id}",
        json.dumps({
            'type': 'job_completed',
            'best_score': best_score,
            'improvement_rate': final_result['improvement']['improvement_rate']
        })
    )
    
    return final_result
```

---

## í”„ë¡ íŠ¸ì—”ë“œ í†µí•©

### AutoImproveSetupPage ìˆ˜ì •

```typescript
// components/AutoImproveSetupPageBlue.tsx
import { useState, useEffect } from 'react';
import { api } from '../lib/api-client';
import { RootCauseAnalysis } from '../types';

export function AutoImproveSetupPageBlue() {
  const [baseEvaluationId, setBaseEvaluationId] = useState('');
  const [rootCauseAnalysis, setRootCauseAnalysis] = useState<RootCauseAnalysis | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  
  // ê·¼ë³¸ ì›ì¸ ë¶„ì„ ì‹¤í–‰
  const handleAnalyze = async () => {
    if (!baseEvaluationId) return;
    
    setIsAnalyzing(true);
    try {
      const response = await api.autoImprove.analyzeRootCause({
        evaluation_id: baseEvaluationId
      });
      
      if (response.success && response.data) {
        setRootCauseAnalysis(response.data);
      }
    } catch (error) {
      console.error('Failed to analyze root cause:', error);
    } finally {
      setIsAnalyzing(false);
    }
  };
  
  // ìë™ ê°œì„  ì‹œì‘
  const handleStartAutoImprove = async () => {
    if (!baseEvaluationId || !rootCauseAnalysis) return;
    
    try {
      const response = await api.autoImprove.create({
        base_evaluation_id: baseEvaluationId,
        strategy: rootCauseAnalysis.recommended_strategy,
        optimization_level: 'rule_based',
        early_stopping: {
          enabled: true,
          min_improvement: 0.05,
          patience: 3,
          target_score: 0.9
        }
      });
      
      if (response.success && response.data) {
        // Progress í˜ì´ì§€ë¡œ ì´ë™
        onNavigate('progress', response.data.job_id);
      }
    } catch (error) {
      console.error('Failed to start auto-improve:', error);
    }
  };
  
  return (
    <div className="space-y-6">
      {/* 1. ê¸°ì¤€ í‰ê°€ ì„ íƒ */}
      <Card>
        <CardHeader>
          <CardTitle>1. ê¸°ì¤€ í‰ê°€ ì„ íƒ</CardTitle>
        </CardHeader>
        <CardContent>
          <Select value={baseEvaluationId} onValueChange={setBaseEvaluationId}>
            {/* ... */}
          </Select>
          
          <Button 
            onClick={handleAnalyze} 
            disabled={!baseEvaluationId || isAnalyzing}
            className="mt-4"
          >
            {isAnalyzing ? 'ë¶„ì„ ì¤‘...' : 'ê·¼ë³¸ ì›ì¸ ë¶„ì„'}
          </Button>
        </CardContent>
      </Card>
      
      {/* 2. ê·¼ë³¸ ì›ì¸ ë¶„ì„ ê²°ê³¼ */}
      {rootCauseAnalysis && (
        <Card>
          <CardHeader>
            <CardTitle>2. ë¶„ì„ ê²°ê³¼</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="space-y-4">
              {/* Retrieval ë¬¸ì œ */}
              {rootCauseAnalysis.root_causes?.retrieval && (
                <div className="p-4 bg-cyan-50 rounded-lg">
                  <h4 className="font-semibold text-cyan-900">ê²€ìƒ‰ í’ˆì§ˆ ê°œì„  í•„ìš”</h4>
                  <p className="text-sm text-cyan-700 mt-1">
                    ì‹¬ê°ë„: {rootCauseAnalysis.root_causes.retrieval.severity}
                  </p>
                  <p className="text-sm text-cyan-700">
                    ì˜í–¥ ë°›ì€ ì§€í‘œ: {rootCauseAnalysis.root_causes.retrieval.affected_metrics.join(', ')}
                  </p>
                  <p className="text-sm text-cyan-700">
                    ìš°ì„  ìµœì í™” íŒŒë¼ë¯¸í„°: {rootCauseAnalysis.root_causes.retrieval.priority_params.join(', ')}
                  </p>
                </div>
              )}
              
              {/* Generation ë¬¸ì œ */}
              {rootCauseAnalysis.root_causes?.generation && (
                <div className="p-4 bg-purple-50 rounded-lg">
                  <h4 className="font-semibold text-purple-900">ìƒì„± í’ˆì§ˆ ê°œì„  í•„ìš”</h4>
                  <p className="text-sm text-purple-700 mt-1">
                    ì‹¬ê°ë„: {rootCauseAnalysis.root_causes.generation.severity}
                  </p>
                  <p className="text-sm text-purple-700">
                    ì˜í–¥ ë°›ì€ ì§€í‘œ: {rootCauseAnalysis.root_causes.generation.affected_metrics.join(', ')}
                  </p>
                  <p className="text-sm text-purple-700">
                    ìš°ì„  ìµœì í™” íŒŒë¼ë¯¸í„°: {rootCauseAnalysis.root_causes.generation.priority_params.join(', ')}
                  </p>
                </div>
              )}
              
              {/* ì¶”ì • ì •ë³´ */}
              <div className="grid grid-cols-3 gap-4 p-4 bg-blue-50 rounded-lg">
                <div>
                  <p className="text-xs text-blue-600">ì˜ˆìƒ ì‹¤í—˜ íšŸìˆ˜</p>
                  <p className="text-xl font-semibold text-blue-900">
                    {rootCauseAnalysis.estimated_experiments}íšŒ
                  </p>
                </div>
                <div>
                  <p className="text-xs text-blue-600">ì˜ˆìƒ ë¹„ìš©</p>
                  <p className="text-xl font-semibold text-blue-900">
                    ${rootCauseAnalysis.estimated_cost.toFixed(2)}
                  </p>
                </div>
                <div>
                  <p className="text-xs text-blue-600">ì˜ˆìƒ ì†Œìš” ì‹œê°„</p>
                  <p className="text-xl font-semibold text-blue-900">
                    {Math.floor(rootCauseAnalysis.estimated_duration_minutes / 60)}ì‹œê°„ {rootCauseAnalysis.estimated_duration_minutes % 60}ë¶„
                  </p>
                </div>
              </div>
              
              {/* ì‹œì‘ ë²„íŠ¼ */}
              <Button 
                onClick={handleStartAutoImprove}
                className="w-full"
              >
                ìë™ ê°œì„  ì‹œì‘ ({rootCauseAnalysis.recommended_strategy})
              </Button>
            </div>
          </CardContent>
        </Card>
      )}
    </div>
  );
}
```

---

## í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: Retrieval ë¬¸ì œ ì¤‘ì‹¬

**ì´ˆê¸° ìƒíƒœ:**
```json
{
  "context_recall": 0.62,
  "context_precision": 0.68,
  "faithfulness": 0.82,
  "answer_relevancy": 0.85
}
```

**ì˜ˆìƒ ë™ì‘:**
1. ê·¼ë³¸ ì›ì¸ ë¶„ì„ â†’ `retrieval_first` ì „ëµ ì„ íƒ
2. ì‹¤í—˜ ìˆœì„œ:
   - Top-K=3 (0.65ì )
   - Top-K=5 (0.72ì ) â† ê°œì„ !
   - Top-K=10 (0.75ì ) â† ê°œì„ !
   - Top-K=15 (0.74ì )
   - Chunk Size=256 (Top-K=10) (0.78ì ) â† ê°œì„ !
   - Chunk Size=1024 (0.76ì )
   - Embedding=3-large (0.85ì ) â† ê°œì„ !
3. Early Stopping: 3íšŒ ì—°ì† ê°œì„  ì—†ìŒ â†’ 8ë²ˆì§¸ ì‹¤í—˜ì—ì„œ ì¢…ë£Œ
4. ìµœì¢… ê°œì„ ìœ¨: +37% (0.62 â†’ 0.85)

### ì‹œë‚˜ë¦¬ì˜¤ 2: Generation ë¬¸ì œ ì¤‘ì‹¬

**ì´ˆê¸° ìƒíƒœ:**
```json
{
  "context_recall": 0.85,
  "faithfulness": 0.65,
  "answer_correctness": 0.68,
  "coherence": 0.72
}
```

**ì˜ˆìƒ ë™ì‘:**
1. ê·¼ë³¸ ì›ì¸ ë¶„ì„ â†’ `generation_first` ì „ëµ ì„ íƒ
2. ì‹¤í—˜ ìˆœì„œ:
   - Temperature=0.1 (0.70ì ) â† ê°œì„ !
   - Temperature=0.3 (0.75ì ) â† ê°œì„ !
   - Temperature=0.5 (0.73ì )
   - Temperature=0.7 (0.68ì )
   - LLM=Claude-3.5 Sonnet (Temp=0.3) (0.88ì ) â† ê°œì„ !
3. Early Stopping: ëª©í‘œ ì ìˆ˜ 0.9ì— ê·¼ì ‘ â†’ 6ë²ˆì§¸ ì‹¤í—˜ì—ì„œ ì¢…ë£Œ
4. ìµœì¢… ê°œì„ ìœ¨: +35% (0.65 â†’ 0.88)

---

## ë‹¤ìŒ ë‹¨ê³„

1. **ë°±ì—”ë“œ êµ¬í˜„** (Week 1-2)
   - [ ] ê·¼ë³¸ ì›ì¸ ë¶„ì„ ë¡œì§
   - [ ] ì‹¤í—˜ ìƒì„± ë¡œì§
   - [ ] Celery íƒœìŠ¤í¬
   - [ ] WebSocket ì„œë²„

2. **í”„ë¡ íŠ¸ì—”ë“œ í†µí•©** (Week 2-3)
   - [ ] AutoImproveSetupPage API ì—°ë™
   - [ ] AutoImproveProgressPage WebSocket ì—°ë™
   - [ ] AutoImproveResultsPage ê²°ê³¼ ì‹œê°í™”

3. **í…ŒìŠ¤íŠ¸** (Week 3-4)
   - [ ] ìœ ë‹› í…ŒìŠ¤íŠ¸
   - [ ] í†µí•© í…ŒìŠ¤íŠ¸
   - [ ] End-to-End í…ŒìŠ¤íŠ¸

4. **ë°°í¬** (Week 4)
   - [ ] Staging í™˜ê²½ ë°°í¬
   - [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
   - [ ] Production ë°°í¬

---

**ì§ˆë¬¸ì´ë‚˜ ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•˜ë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!**
