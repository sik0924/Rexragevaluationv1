# V1.0 í”„ë¡œë•ì…˜ ì¤€ë¹„ ê°€ì´ë“œ

## ğŸ¯ ê°œìš”

ì´ ë¬¸ì„œëŠ” REX V1.0ì˜ **í”„ë¡œë•ì…˜ ë°°í¬ ì•ˆì •ì„±**ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ 5ê°€ì§€ í•µì‹¬ ê°œì„  ì‚¬í•­ì„ ì •ë¦¬í•©ë‹ˆë‹¤. ê° í•­ëª©ì€ ì‹ë³„ëœ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­(Technical Details)ì´ë©°, V1.0 ë°°í¬ ì „ ë°˜ë“œì‹œ êµ¬ì²´í™”í•´ì•¼ í•©ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [LLM Judge ì•ˆì •ì„± ë° ë””ë²„ê¹…](#1-llm-judge-ì•ˆì •ì„±-ë°-ë””ë²„ê¹…)
2. [ë¹„ìš© ê´€ì œ ì‹ ë¢°ì„± í™•ë³´](#2-ë¹„ìš©-ê´€ì œ-ì‹ ë¢°ì„±-í™•ë³´)
3. [í‰ê°€ ì—”ì§„ í†µí•© ë° ì˜¤ë¥˜ ì²˜ë¦¬](#3-í‰ê°€-ì—”ì§„-í†µí•©-ë°-ì˜¤ë¥˜-ì²˜ë¦¬)
4. [ë°°í¬ ë° ëª¨ë‹ˆí„°ë§ í™˜ê²½ ì •ì˜](#4-ë°°í¬-ë°-ëª¨ë‹ˆí„°ë§-í™˜ê²½-ì •ì˜)
5. [í”„ë¡ íŠ¸ì—”ë“œ ìœ ì—°ì„± í™•ì¥](#5-í”„ë¡ íŠ¸ì—”ë“œ-ìœ ì—°ì„±-í™•ì¥)

---

## 1. LLM Judge ì•ˆì •ì„± ë° ë””ë²„ê¹…

### 1.1 Guardrail ì‹¤íŒ¨ ì‹œ ìµœì¢… ì²˜ë¦¬

**ë¬¸ì œ:**  
LLM Judgeê°€ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ì§€ ëª»í•  ê²½ìš° (ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨), ì„œë²„ëŠ” ì–´ë–»ê²Œ ì‘ë‹µí•˜ê³  ë¡œê·¸ë¥¼ ë‚¨ê²¨ì•¼ í•˜ëŠ”ê°€?

**í•´ê²° ë°©ì•ˆ:**

#### a) ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ í™•ì¥

```sql
-- failed_cases í…Œì´ë¸”ì— í•„ë“œ ì¶”ê°€
ALTER TABLE failed_cases 
ADD COLUMN raw_llm_output TEXT,           -- íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ LLM ì‘ë‹µ ì €ì¥
ADD COLUMN llm_parsing_failed BOOLEAN DEFAULT FALSE;  -- íŒŒì‹± ì‹¤íŒ¨ í”Œë˜ê·¸
```

#### b) TypeScript íƒ€ì… ì •ì˜

```typescript
// types/index.ts
export interface LLMJudgeAnalysis {
  failure_type: 'Retrieval' | 'Generation';
  reason: string;
  root_cause: {
    summary_ko: string;
    advice_ko: string;
  };
  llm_model: string;
  prompt_version: string;
  confidence: number;
  analyzed_at: string;
  
  // ğŸŒŸ ìƒˆë¡œ ì¶”ê°€
  raw_llm_output?: string;      // íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì €ì¥
  parsing_failed?: boolean;     // íŒŒì‹± ì‹¤íŒ¨ í”Œë˜ê·¸
}
```

#### c) í”„ë¡ íŠ¸ì—”ë“œ UI ì²˜ë¦¬

```typescript
// DiagnosisSummaryCard.tsx ë˜ëŠ” ResultsPageBlue.tsx
{failedCase.llmJudgeAnalysis?.parsing_failed && (
  <Alert variant="destructive">
    <AlertTriangle className="h-4 w-4" />
    <AlertTitle>LLM Judge ë¶„ì„ ì˜¤ë¥˜</AlertTitle>
    <AlertDescription>
      LLM Judge ë¶„ì„ ì¤‘ JSON íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. 
      ì›ë³¸ ì‘ë‹µì´ ë¡œê·¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
      
      <Button 
        variant="outline" 
        size="sm" 
        className="mt-2"
        onClick={() => showRawOutput(failedCase.llmJudgeAnalysis.raw_llm_output)}
      >
        ì›ë³¸ ì‘ë‹µ ë³´ê¸°
      </Button>
    </AlertDescription>
  </Alert>
)}
```

#### d) ë°±ì—”ë“œ ì²˜ë¦¬ ë¡œì§

```python
# diagnosis_pipeline.py
def run_llm_judge(failed_case):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            raw_response = call_gpt4(failed_case, prompt_version='v1.2')
            parsed_result = json.loads(raw_response)
            validate_schema(parsed_result)
            return parsed_result
        except (JSONDecodeError, SchemaValidationError) as e:
            if attempt == max_retries - 1:
                # ìµœì¢… ì‹¤íŒ¨: ì›ë³¸ ì €ì¥
                return {
                    'parsing_failed': True,
                    'raw_llm_output': raw_response,
                    'error': str(e)
                }
            time.sleep(5)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
```

**ì™„ë£Œ ê¸°ì¤€:**
- [x] TypeScript íƒ€ì…ì— `raw_llm_output`, `parsing_failed` ì¶”ê°€ âœ…
- [ ] ë°±ì—”ë“œ DB ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸
- [ ] ë°±ì—”ë“œ íŒŒì‹± ì‹¤íŒ¨ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„
- [ ] í”„ë¡ íŠ¸ì—”ë“œ UI íŒŒì‹± ì‹¤íŒ¨ ì•Œë¦¼ ì¶”ê°€

---

### 1.2 í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ ë° A/B í…ŒìŠ¤íŠ¸

**ë¬¸ì œ:**  
í”„ë¡¬í”„íŠ¸ ê°œì„  ì‹œ ì´ì „ ë²„ì „ê³¼ì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ì–´ë–»ê²Œ í•  ê²ƒì¸ê°€?

**í•´ê²° ë°©ì•ˆ:**

#### a) ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

```sql
-- LLM Judge í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ í…Œì´ë¸”
CREATE TABLE llm_judge_prompts (
    id SERIAL PRIMARY KEY,
    version VARCHAR(20) UNIQUE NOT NULL,
    template TEXT NOT NULL,
    description TEXT,
    is_active BOOLEAN DEFAULT FALSE,
    test_group VARCHAR(10),  -- 'A', 'B', 'control', NULL
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(100),
    
    -- ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ì§‘ê³„ìš©)
    avg_confidence DECIMAL(5,4),
    parsing_success_rate DECIMAL(5,4),
    avg_response_time_ms INTEGER
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_llm_judge_prompts_active ON llm_judge_prompts(is_active);
CREATE INDEX idx_llm_judge_prompts_test_group ON llm_judge_prompts(test_group);
```

#### b) TypeScript íƒ€ì…

```typescript
// types/index.ts - ì´ë¯¸ ì¶”ê°€ë¨ âœ…
export interface LLMJudgePromptVersion {
  id: string;
  version: string;
  template: string;
  description?: string;
  is_active: boolean;
  test_group?: 'A' | 'B' | 'control';
  created_at: string;
  created_by?: string;
  performance_metrics?: {
    avg_confidence: number;
    parsing_success_rate: number;
    avg_response_time_ms: number;
  };
}
```

#### c) API ì—”ë“œí¬ì¸íŠ¸

```typescript
// lib/api-client.tsì— ì¶”ê°€
export const llmJudgeApi = {
  /**
   * í”„ë¡¬í”„íŠ¸ ë²„ì „ ëª©ë¡ ì¡°íšŒ
   */
  listPrompts: async () => {
    return apiClient.get<{
      prompts: LLMJudgePromptVersion[]
    }>('/llm-judge/prompts');
  },

  /**
   * í”„ë¡¬í”„íŠ¸ ë²„ì „ ìƒì„±
   */
  createPrompt: async (request: {
    version: string;
    template: string;
    description?: string;
    test_group?: 'A' | 'B' | 'control';
  }) => {
    return apiClient.post<LLMJudgePromptVersion>('/llm-judge/prompts', request);
  },

  /**
   * í™œì„± í”„ë¡¬í”„íŠ¸ ì„¤ì •
   */
  setActivePrompt: async (version: string) => {
    return apiClient.post<{ message: string }>(`/llm-judge/prompts/${version}/activate`, {});
  },

  /**
   * í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ë¹„êµ
   */
  comparePrompts: async (versionA: string, versionB: string) => {
    return apiClient.get<{
      version_a: LLMJudgePromptVersion;
      version_b: LLMJudgePromptVersion;
      comparison: {
        confidence_diff: number;
        parsing_success_diff: number;
        response_time_diff: number;
      };
    }>('/llm-judge/prompts/compare', { version_a: versionA, version_b: versionB });
  },
};
```

#### d) ê´€ë¦¬ì í˜ì´ì§€ UI (AdminPageBlue.tsxì— ì¶”ê°€)

```typescript
// ìƒˆ íƒ­: "LLM Judge í”„ë¡¬í”„íŠ¸ ê´€ë¦¬"
<TabsContent value="llm-judge-prompts">
  <Card>
    <CardHeader>
      <CardTitle>LLM Judge í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬</CardTitle>
      <CardDescription>
        í”„ë¡¬í”„íŠ¸ ë²„ì „ì„ ê´€ë¦¬í•˜ê³  A/B í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤
      </CardDescription>
    </CardHeader>
    <CardContent>
      <Table>
        <TableHeader>
          <TableRow>
            <TableHead>ë²„ì „</TableHead>
            <TableHead>ìƒíƒœ</TableHead>
            <TableHead>í…ŒìŠ¤íŠ¸ ê·¸ë£¹</TableHead>
            <TableHead>í‰ê·  ì‹ ë¢°ë„</TableHead>
            <TableHead>íŒŒì‹± ì„±ê³µë¥ </TableHead>
            <TableHead>ì‘ì—…</TableHead>
          </TableRow>
        </TableHeader>
        <TableBody>
          {promptVersions.map(prompt => (
            <TableRow key={prompt.id}>
              <TableCell>{prompt.version}</TableCell>
              <TableCell>
                {prompt.is_active && <Badge>í™œì„±</Badge>}
              </TableCell>
              <TableCell>{prompt.test_group || '-'}</TableCell>
              <TableCell>{prompt.performance_metrics?.avg_confidence.toFixed(2)}</TableCell>
              <TableCell>{(prompt.performance_metrics?.parsing_success_rate * 100).toFixed(1)}%</TableCell>
              <TableCell>
                <Button 
                  size="sm" 
                  onClick={() => setActivePrompt(prompt.version)}
                  disabled={prompt.is_active}
                >
                  í™œì„±í™”
                </Button>
              </TableCell>
            </TableRow>
          ))}
        </TableBody>
      </Table>
    </CardContent>
  </Card>
</TabsContent>
```

**ì™„ë£Œ ê¸°ì¤€:**
- [x] TypeScript íƒ€ì… ì •ì˜ ì™„ë£Œ âœ…
- [ ] API í´ë¼ì´ì–¸íŠ¸ í•¨ìˆ˜ ì¶”ê°€
- [ ] ë°±ì—”ë“œ DB í…Œì´ë¸” ìƒì„±
- [ ] ë°±ì—”ë“œ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ API êµ¬í˜„
- [ ] ê´€ë¦¬ì í˜ì´ì§€ UI ì¶”ê°€ (V1.5)

---

## 2. ë¹„ìš© ê´€ì œ ì‹ ë¢°ì„± í™•ë³´

### 2.1 LLM ê°€ê²© ì •ë³´ì˜ Source of Truth

**ë¬¸ì œ:**  
LLM ëª¨ë¸ë³„ ê°€ê²©ì´ ë³€ë™ë  ë•Œ ì–´ë–»ê²Œ ì—…ë°ì´íŠ¸í•˜ê³  ê´€ë¦¬í•  ê²ƒì¸ê°€?

**í•´ê²° ë°©ì•ˆ:**

#### a) ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

```sql
-- LLM ê°€ê²© ì •ë³´ í…Œì´ë¸”
CREATE TABLE llm_pricing (
    id SERIAL PRIMARY KEY,
    model_id VARCHAR(50) UNIQUE NOT NULL,
    model_name VARCHAR(100) NOT NULL,
    provider VARCHAR(50) NOT NULL,  -- 'OpenAI', 'Anthropic', 'Google', etc.
    input_price_per_1k_tokens DECIMAL(10,6) NOT NULL,
    output_price_per_1k_tokens DECIMAL(10,6) NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_by VARCHAR(100)
);

-- ê°€ê²© ë³€ê²½ íˆìŠ¤í† ë¦¬ (ê°ì‚¬ìš©)
CREATE TABLE llm_pricing_history (
    id SERIAL PRIMARY KEY,
    model_id VARCHAR(50) NOT NULL,
    old_input_price DECIMAL(10,6),
    new_input_price DECIMAL(10,6),
    old_output_price DECIMAL(10,6),
    new_output_price DECIMAL(10,6),
    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    changed_by VARCHAR(100),
    reason TEXT
);
```

#### b) TypeScript íƒ€ì… (ì´ë¯¸ ì •ì˜ë¨ âœ…)

```typescript
// types/index.ts
export interface LLMPricing {
  model_id: string;
  model_name: string;
  provider: string;
  input_price_per_1k_tokens: number;
  output_price_per_1k_tokens: number;
  last_updated: string;
  is_active: boolean;
}

export interface LLMPricingHistory {
  id: string;
  model_id: string;
  old_input_price: number;
  new_input_price: number;
  old_output_price: number;
  new_output_price: number;
  changed_at: string;
  changed_by: string;
  reason?: string;
}
```

#### c) API í´ë¼ì´ì–¸íŠ¸ (ì´ë¯¸ ì •ì˜ë¨ âœ…)

```typescript
// lib/api-client.ts - costApiì— ì´ë¯¸ ì¡´ì¬
export const costApi = {
  /**
   * LLM ê°€ê²© ì •ë³´ ì¡°íšŒ
   */
  getPricing: async () => {
    return apiClient.get<{
      pricing: LLMPricing[];
      last_updated: string;
    }>('/costs/pricing');
  },

  /**
   * LLM ê°€ê²© ì •ë³´ ì—…ë°ì´íŠ¸ (ê´€ë¦¬ì ì „ìš©)
   */
  updatePricing: async (model_id: string, request: {
    input_price_per_1k_tokens: number;
    output_price_per_1k_tokens: number;
    reason?: string;
  }) => {
    return apiClient.put<LLMPricing>(`/costs/pricing/${model_id}`, request);
  },

  /**
   * ê°€ê²© ë³€ê²½ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
   */
  getPricingHistory: async (model_id?: string) => {
    return apiClient.get<{
      history: LLMPricingHistory[];
    }>('/costs/pricing/history', model_id ? { model_id } : undefined);
  },
};
```

#### d) ê´€ë¦¬ì í˜ì´ì§€ UI (AdminPageBlue.tsxì— ì¶”ê°€)

```typescript
// ìƒˆ íƒ­: "LLM ê°€ê²© ê´€ë¦¬"
<TabsContent value="llm-pricing">
  <Card>
    <CardHeader>
      <div className="flex items-center justify-between">
        <div>
          <CardTitle>LLM ê°€ê²© ì •ë³´ ê´€ë¦¬</CardTitle>
          <CardDescription>
            LLM ëª¨ë¸ë³„ í† í° ê°€ê²©ì„ ê´€ë¦¬í•©ë‹ˆë‹¤
          </CardDescription>
        </div>
        <Button onClick={refreshPricing}>
          <RefreshCw className="h-4 w-4 mr-2" />
          ê°€ê²© ì •ë³´ ê°±ì‹ 
        </Button>
      </div>
    </CardHeader>
    <CardContent>
      <Table>
        <TableHeader>
          <TableRow>
            <TableHead>ëª¨ë¸</TableHead>
            <TableHead>ì œê³µì‚¬</TableHead>
            <TableHead>Input ($/ 1K tokens)</TableHead>
            <TableHead>Output ($/ 1K tokens)</TableHead>
            <TableHead>ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸</TableHead>
            <TableHead>ì‘ì—…</TableHead>
          </TableRow>
        </TableHeader>
        <TableBody>
          {pricingList.map(pricing => (
            <TableRow key={pricing.model_id}>
              <TableCell>{pricing.model_name}</TableCell>
              <TableCell>{pricing.provider}</TableCell>
              <TableCell>${pricing.input_price_per_1k_tokens.toFixed(4)}</TableCell>
              <TableCell>${pricing.output_price_per_1k_tokens.toFixed(4)}</TableCell>
              <TableCell>{new Date(pricing.last_updated).toLocaleDateString()}</TableCell>
              <TableCell>
                <Button 
                  size="sm" 
                  variant="outline"
                  onClick={() => openPricingEditDialog(pricing)}
                >
                  ìˆ˜ì •
                </Button>
              </TableCell>
            </TableRow>
          ))}
        </TableBody>
      </Table>

      {/* ê°€ê²© ë³€ê²½ íˆìŠ¤í† ë¦¬ */}
      <Separator className="my-6" />
      <h3 className="text-lg font-semibold mb-4">ê°€ê²© ë³€ê²½ íˆìŠ¤í† ë¦¬</h3>
      <Table>
        <TableHeader>
          <TableRow>
            <TableHead>ëª¨ë¸</TableHead>
            <TableHead>ë³€ê²½ ì „</TableHead>
            <TableHead>ë³€ê²½ í›„</TableHead>
            <TableHead>ë³€ê²½ ì¼ì‹œ</TableHead>
            <TableHead>ë³€ê²½ì</TableHead>
            <TableHead>ì‚¬ìœ </TableHead>
          </TableRow>
        </TableHeader>
        <TableBody>
          {pricingHistory.map(history => (
            <TableRow key={history.id}>
              <TableCell>{history.model_id}</TableCell>
              <TableCell>
                ${history.old_input_price.toFixed(4)} / ${history.old_output_price.toFixed(4)}
              </TableCell>
              <TableCell>
                ${history.new_input_price.toFixed(4)} / ${history.new_output_price.toFixed(4)}
              </TableCell>
              <TableCell>{new Date(history.changed_at).toLocaleString()}</TableCell>
              <TableCell>{history.changed_by}</TableCell>
              <TableCell>{history.reason || '-'}</TableCell>
            </TableRow>
          ))}
        </TableBody>
      </Table>
    </CardContent>
  </Card>
</TabsContent>
```

**ì™„ë£Œ ê¸°ì¤€:**
- [x] TypeScript íƒ€ì… ì •ì˜ ì™„ë£Œ âœ…
- [x] API í´ë¼ì´ì–¸íŠ¸ í•¨ìˆ˜ ì¡´ì¬ âœ…
- [ ] ë°±ì—”ë“œ DB í…Œì´ë¸” ìƒì„±
- [ ] ë°±ì—”ë“œ ê°€ê²© ê´€ë¦¬ API êµ¬í˜„
- [ ] ê´€ë¦¬ì í˜ì´ì§€ UI ì¶”ê°€

---

### 2.2 ë¹„ìš© ì˜ˆì¸¡ ìˆ˜í•™ì  ëª¨ë¸ ì •ì˜

**ë¬¸ì œ:**  
`POST /costs/predict` APIì˜ ë¹„ìš© ê³„ì‚° ë¡œì§ì„ ëª…í™•íˆ ë¬¸ì„œí™”í•´ì•¼ í•¨

**í•´ê²° ë°©ì•ˆ:**

#### ìˆ˜ì‹ ì •ì˜

```
ì´ ë¹„ìš© = LLM ìƒì„± ë¹„ìš© + LLM Judge ë¹„ìš©

LLM ìƒì„± ë¹„ìš© = Î£ (Input Tokens Ã— Input Price + Output Tokens Ã— Output Price)
  - Input Tokens  = (Context Tokens + Question Tokens) Ã— Dataset Size
  - Output Tokens = Avg Answer Length Ã— Dataset Size

LLM Judge ë¹„ìš© = Î£ (LLM Judge Input Ã— Input Price + LLM Judge Output Ã— Output Price) Ã— Sampled Cases
  - Sampled Cases = Total Failed Cases Ã— Sampling Rate
  - LLM Judge Input  = (Question + Answer + Context) Tokens
  - LLM Judge Output = Avg Analysis Tokens (~500)
```

#### ì˜ˆì‹œ ê³„ì‚°

```python
# ì˜ˆì‹œ: GPT-4o ê¸°ì¤€
dataset_size = 100
avg_context_tokens = 2000
avg_question_tokens = 50
avg_answer_tokens = 200

# 1. LLM ìƒì„± ë¹„ìš©
input_tokens_per_qa = avg_context_tokens + avg_question_tokens  # 2050
output_tokens_per_qa = avg_answer_tokens  # 200

total_input_tokens = input_tokens_per_qa * dataset_size  # 205,000
total_output_tokens = output_tokens_per_qa * dataset_size  # 20,000

gpt4_input_price = 0.005  # $0.005 per 1K tokens
gpt4_output_price = 0.015  # $0.015 per 1K tokens

generation_cost = (total_input_tokens / 1000 * gpt4_input_price) + \
                  (total_output_tokens / 1000 * gpt4_output_price)
# = (205 * 0.005) + (20 * 0.015) = $1.025 + $0.30 = $1.325

# 2. LLM Judge ë¹„ìš©
failed_cases = 15  # 15ê°œ ì‹¤íŒ¨ (ì‹¤íŒ¨ìœ¨ 15%)
sampling_rate = 0.2  # 20% ìƒ˜í”Œë§
sampled_cases = failed_cases * sampling_rate  # 3ê°œ

llm_judge_input_tokens_per_case = (avg_question_tokens + avg_answer_tokens + avg_context_tokens)  # 2250
llm_judge_output_tokens_per_case = 500  # ë¶„ì„ ê²°ê³¼

llm_judge_cost = sampled_cases * (
    (llm_judge_input_tokens_per_case / 1000 * gpt4_input_price) +
    (llm_judge_output_tokens_per_case / 1000 * gpt4_output_price)
)
# = 3 * ((2.25 * 0.005) + (0.5 * 0.015))
# = 3 * (0.01125 + 0.0075) = 3 * 0.01875 = $0.05625

# ì´ ë¹„ìš©
total_cost = generation_cost + llm_judge_cost
# = $1.325 + $0.05625 = $1.38125
```

#### ë¬¸ì„œí™”

`/guidelines/Score-Analysis-Algorithm.md`ì— ì¶”ê°€:

```markdown
## ë¹„ìš© ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜

### ìˆ˜ì‹

$$
\text{Total Cost} = \text{LLM Generation Cost} + \text{LLM Judge Cost}
$$

$$
\text{LLM Generation Cost} = \sum_{i=1}^{N} \left( \frac{T_{input}^{(i)}}{1000} \times P_{input} + \frac{T_{output}^{(i)}}{1000} \times P_{output} \right)
$$

$$
\text{LLM Judge Cost} = \sum_{j=1}^{M} \left( \frac{T_{judge\_input}^{(j)}}{1000} \times P_{input} + \frac{T_{judge\_output}^{(j)}}{1000} \times P_{output} \right)
$$

ì—¬ê¸°ì„œ:
- $N$ = ë°ì´í„°ì…‹ í¬ê¸°
- $M$ = ìƒ˜í”Œë§ëœ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ìˆ˜
- $T_{input}$ = Input í† í° ìˆ˜
- $T_{output}$ = Output í† í° ìˆ˜
- $P_{input}$ = Input ê°€ê²© ($ per 1K tokens)
- $P_{output}$ = Output ê°€ê²© ($ per 1K tokens)
```

**ì™„ë£Œ ê¸°ì¤€:**
- [ ] ìˆ˜ì‹ ì •ì˜ ë° ë¬¸ì„œí™”
- [ ] ë°±ì—”ë“œ ë¹„ìš© ì˜ˆì¸¡ API êµ¬í˜„
- [ ] í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë¹„ìš© ì˜ˆì¸¡ API í˜¸ì¶œ ë° í‘œì‹œ

---

## 3. í‰ê°€ ì—”ì§„ í†µí•© ë° ì˜¤ë¥˜ ì²˜ë¦¬

### 3.1 ì‹¤íŒ¨í•œ í‰ê°€ ì‘ì—…ì˜ ì¬ì‹¤í–‰ ë¡œì§

**ë¬¸ì œ:**  
RAGAS/KRAG ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹¤í–‰ ì¤‘ ë©”ëª¨ë¦¬ ì˜¤ë¥˜ë‚˜ API íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ ì–´ë–»ê²Œ ì²˜ë¦¬í•  ê²ƒì¸ê°€?

**í•´ê²° ë°©ì•ˆ:**

#### a) TypeScript íƒ€ì… í™•ì¥ (ì™„ë£Œ âœ…)

```typescript
// types/index.ts
export type EvaluationStatus = 
  | 'pending' 
  | 'running' 
  | 'completed' 
  | 'failed' 
  | 'stopped' 
  | 'scheduled'
  | 'retrying';  // ğŸŒŸ ì¶”ê°€ë¨

export interface EvaluationStatusResponse {
  id: string;
  status: EvaluationStatus;
  progress: number;
  currentTask?: string;
  metricsProcessed?: Record<string, number>;
  estimatedCompletion?: string;
  retry_count?: number;        // ğŸŒŸ ì¬ì‹œë„ íšŸìˆ˜
  max_retries?: number;        // ğŸŒŸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
  last_error?: string;         // ğŸŒŸ ë§ˆì§€ë§‰ ì˜¤ë¥˜ ë©”ì‹œì§€
}
```

#### b) ë°±ì—”ë“œ ì¬ì‹œë„ ì •ì±…

```python
# tasks.py (Python RQ)
from rq import Retry

@job(
    'evaluations',
    retry=Retry(max=3, interval=[60, 300, 900]),  # 1ë¶„, 5ë¶„, 15ë¶„ í›„ ì¬ì‹œë„
    timeout=3600  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ
)
def run_evaluation(evaluation_id):
    try:
        # RAGAS/KRAG ì‹¤í–‰
        results = ragas.evaluate(...)
        save_results(evaluation_id, results)
        
    except MemoryError as e:
        logger.error(f"Memory error in evaluation {evaluation_id}: {e}")
        # ì¬ì‹œë„ ì‹œ ë” ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ ì‹¤í–‰
        raise  # RQê°€ ìë™ ì¬ì‹œë„
        
    except APITimeoutError as e:
        logger.warning(f"API timeout in evaluation {evaluation_id}: {e}")
        # ì¬ì‹œë„ ì‹œ ë ˆì´íŠ¸ ë¦¬ë°‹ ê³ ë ¤
        raise
        
    except Exception as e:
        logger.error(f"Unexpected error in evaluation {evaluation_id}: {e}")
        # ìµœì¢… ì‹¤íŒ¨ ì²˜ë¦¬
        mark_evaluation_as_failed(evaluation_id, str(e))
```

#### c) í”„ë¡ íŠ¸ì—”ë“œ UI (EvaluationMonitorPageBlue.tsx)

```typescript
// ì¬ì‹œë„ ìƒíƒœ í‘œì‹œ
{evaluation.status === 'retrying' && (
  <Alert className="border-yellow-500 bg-yellow-50">
    <AlertTriangle className="h-4 w-4 text-yellow-600" />
    <AlertTitle className="text-yellow-900">í‰ê°€ ì¬ì‹œë„ ì¤‘</AlertTitle>
    <AlertDescription className="text-yellow-800">
      í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ìë™ìœ¼ë¡œ ì¬ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.
      <div className="mt-2 space-y-1">
        <p>ì¬ì‹œë„ íšŸìˆ˜: {evaluation.retry_count}/{evaluation.max_retries}</p>
        <p className="text-sm">ë§ˆì§€ë§‰ ì˜¤ë¥˜: {evaluation.last_error}</p>
      </div>
      <Progress 
        value={(evaluation.retry_count / evaluation.max_retries) * 100} 
        className="mt-2"
      />
    </AlertDescription>
  </Alert>
)}

// ìµœì¢… ì‹¤íŒ¨ í‘œì‹œ
{evaluation.status === 'failed' && (
  <Alert variant="destructive">
    <XCircle className="h-4 w-4" />
    <AlertTitle>í‰ê°€ ì‹¤íŒ¨</AlertTitle>
    <AlertDescription>
      {evaluation.max_retries}ë²ˆì˜ ì¬ì‹œë„ í›„ì—ë„ í‰ê°€ë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
      <p className="mt-2 text-sm">ì˜¤ë¥˜: {evaluation.last_error}</p>
      <div className="mt-4 flex gap-2">
        <Button 
          size="sm" 
          variant="outline"
          onClick={() => retryEvaluation(evaluation.id)}
        >
          ìˆ˜ë™ ì¬ì‹œë„
        </Button>
        <Button 
          size="sm" 
          variant="outline"
          onClick={() => viewLogs(evaluation.id)}
        >
          ë¡œê·¸ ë³´ê¸°
        </Button>
      </div>
    </AlertDescription>
  </Alert>
)}
```

**ì™„ë£Œ ê¸°ì¤€:**
- [x] TypeScript íƒ€ì… `'retrying'` ìƒíƒœ ì¶”ê°€ âœ…
- [x] TypeScript íƒ€ì… `retry_count`, `max_retries`, `last_error` ì¶”ê°€ âœ…
- [ ] ë°±ì—”ë“œ ì¬ì‹œë„ ì •ì±… êµ¬í˜„ (Python RQ Retry)
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ì¬ì‹œë„ ìƒíƒœ UI ì¶”ê°€

---

### 3.2 ì»¤ìŠ¤í…€ ì§€í‘œ ê¸°ëŠ¥

**ë¬¸ì œ:**  
ì»¤ìŠ¤í…€ ì§€í‘œ ì¶”ê°€ ê¸°ëŠ¥ì„ V1.0ì— í¬í•¨í• ì§€, ì•„ë‹ˆë©´ API ìŠ¤í™ë§Œ ì •ì˜í• ì§€ í™•ì • í•„ìš”

**ê¶Œì¥ ì‚¬í•­: V1.5ë¡œ ì—°ê¸°, API ìŠ¤í™ë§Œ ì •ì˜**

#### API ìŠ¤í™ (V1.5 ì¤€ë¹„ìš©)

```typescript
// lib/api-client.ts
export const metricsApi = {
  /**
   * ì»¤ìŠ¤í…€ ì§€í‘œ ë“±ë¡
   */
  registerCustomMetric: async (request: {
    name: string;
    description: string;
    category: MetricCategory;
    evaluation_function: string;  // Python ì½”ë“œ ë˜ëŠ” í•¨ìˆ˜ëª…
    parameters?: Record<string, any>;
  }) => {
    return apiClient.post<EvaluationMetric>('/metrics/register', request);
  },

  /**
   * ì»¤ìŠ¤í…€ ì§€í‘œ í…ŒìŠ¤íŠ¸
   */
  testCustomMetric: async (metric_id: string, sample_data: {
    question: string;
    answer: string;
    context: string;
  }) => {
    return apiClient.post<{
      score: number;
      execution_time_ms: number;
    }>(`/metrics/${metric_id}/test`, sample_data);
  },
};
```

**V1.0 Action:**
- [ ] API ìŠ¤í™ë§Œ ì •ì˜ (ìœ„ ì½”ë“œ)
- [ ] V1.5 ë°±ë¡œê·¸ì— ì¶”ê°€
- [ ] ë¬¸ì„œì— "í–¥í›„ ê³„íš" ì„¹ì…˜ ì¶”ê°€

**ì™„ë£Œ ê¸°ì¤€:**
- [ ] API ìŠ¤í™ ë¬¸ì„œí™”
- [ ] V1.5 ë¡œë“œë§µì— ë°˜ì˜

---

## 4. ë°°í¬ ë° ëª¨ë‹ˆí„°ë§ í™˜ê²½ ì •ì˜

### 4.1 ë¡œê¹…/ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„ íƒ

**ë¬¸ì œ:**  
LogViewerPageBlue.tsx UIì— ë°ì´í„°ë¥¼ ì œê³µí•  êµ¬ì²´ì ì¸ ë¡œê¹… ì‹œìŠ¤í…œ í™•ì • í•„ìš”

**ê¶Œì¥ ì•„í‚¤í…ì²˜:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application Layer                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ FastAPI      â”‚â”€â”€â”€â–¶â”‚ Python Logging   â”‚  â”‚
â”‚ â”‚ (Backend)    â”‚    â”‚ (JSON Format)    â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚              â”‚
â”‚                              â–¼              â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                     â”‚ Loguru / structlogâ”‚  â”‚
â”‚                     â”‚ (Structured Logs) â”‚  â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Log Storage & Processing                    â”‚
â”‚                                              â”‚
â”‚  PoC/Dev:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ File-based Logs  â”‚â”€â”€â–¶ /var/log/rex/  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                              â”‚
â”‚  V1.0 Production:                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Elasticsearch    â”‚â—€â”€â”€â”€â”‚ Filebeat     â”‚ â”‚
â”‚  â”‚ (Log Storage)    â”‚    â”‚ (Log Shipper)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â”‚                                  â”‚
â”‚          â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ Kibana           â”‚                      â”‚
â”‚  â”‚ (Visualization)  â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–²
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monitoring Layer     â”‚                      â”‚
â”‚                      â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Prometheus (Metrics Collection)       â”‚ â”‚
â”‚  â”‚  - API Request Rate                   â”‚ â”‚
â”‚  â”‚  - Job Queue Length                   â”‚ â”‚
â”‚  â”‚  - Evaluation Duration                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚                      â”‚
â”‚                      â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Grafana (Dashboard & Alerts)          â”‚ â”‚
â”‚  â”‚  - Real-time System Status            â”‚ â”‚
â”‚  â”‚  - Cost Tracking                      â”‚ â”‚
â”‚  â”‚  - Performance Metrics                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### V1.0 ìµœì†Œ êµ¬ì„± (PoC)

```python
# backend/config/logging.py
import logging
from pythonjsonlogger import jsonlogger

# JSON í¬ë§· ë¡œê±° ì„¤ì •
logger = logging.getLogger('rex')
logHandler = logging.FileHandler('/var/log/rex/app.json')
formatter = jsonlogger.JsonFormatter(
    '%(timestamp)s %(level)s %(name)s %(message)s %(evaluation_id)s %(user_id)s'
)
logHandler.setFormatter(formatter)
logger.addHandler(logHandler)
logger.setLevel(logging.INFO)
```

#### API ì—”ë“œí¬ì¸íŠ¸ (ì´ë¯¸ ì •ì˜ë¨ âœ…)

```typescript
// lib/api-client.ts - adminApi
export const adminApi = {
  /**
   * ë¡œê·¸ ì¡°íšŒ
   */
  getLogs: async (params?: PaginationParams & {
    level?: string;
    session_id?: string;
    start_date?: string;
    end_date?: string;
  }) => {
    return apiClient.get<{ logs: LogEntry[] }>('/logs', params);
  },
};
```

#### í”„ë¡ íŠ¸ì—”ë“œ (ì´ë¯¸ ì™„ì„± âœ…)

- `LogViewerPageBlue.tsx` ì™„ì„±ë˜ì–´ ìˆìŒ
- `/api/v1/logs` ì—”ë“œí¬ì¸íŠ¸ë§Œ ì—°ê²°í•˜ë©´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥

**ì™„ë£Œ ê¸°ì¤€:**
- [ ] ë°±ì—”ë“œ JSON ë¡œê¹… ì„¤ì •
- [ ] Filebeat ì„¤ì • (V1.0 í”„ë¡œë•ì…˜)
- [ ] Elasticsearch + Kibana ì„¤ì • (V1.0 í”„ë¡œë•ì…˜)
- [ ] Prometheus + Grafana ì„¤ì • (V1.0 í”„ë¡œë•ì…˜)
- [x] í”„ë¡ íŠ¸ì—”ë“œ ì¤€ë¹„ ì™„ë£Œ âœ…

---

## 5. í”„ë¡ íŠ¸ì—”ë“œ ìœ ì—°ì„± í™•ì¥

### 5.1 íŒŒë¼ë¯¸í„° ë™ì  ë¡œë”©

**ë¬¸ì œ:**  
RAG íŒŒë¼ë¯¸í„°ì˜ ìœ íš¨ ë²”ìœ„ê°€ LLM ëª¨ë¸ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ

**í•´ê²° ë°©ì•ˆ:**

#### a) API ì—”ë“œí¬ì¸íŠ¸ (ì´ë¯¸ ì¶”ê°€ë¨ âœ…)

```typescript
// lib/api-client.ts
export const resourcesApi = {
  /**
   * RAG íŒŒë¼ë¯¸í„° ì„¤ì • ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ë™ì  ë²”ìœ„)
   */
  getConfigMetadata: async (params?: { model_id?: string }) => {
    return apiClient.get<{
      rag_params: {
        top_k: { min: number; max: number; default: number; step: number };
        chunk_size: { min: number; max: number; default: number; step: number };
        chunk_overlap: { min: number; max: number; default: number; step: number };
        similarity_threshold: { min: number; max: number; default: number; step: number };
        retriever_types: Array<'semantic' | 'hybrid' | 'keyword'>;
      };
      llm_judge_params: {
        score_threshold: { min: number; max: number; default: number };
        context_recall_threshold: { min: number; max: number; default: number };
        min_context_tokens: { min: number; max: number; default: number };
      };
    }>('/config/params', params);
  },
};
```

#### b) NewEvaluationPageBlue.tsx ë™ì  ë¡œë”©

```typescript
// NewEvaluationPageBlue.tsxì— ì¶”ê°€
const [paramRanges, setParamRanges] = useState<any>(null);

// ëª¨ë¸ ì„ íƒ ì‹œ íŒŒë¼ë¯¸í„° ë²”ìœ„ ë¡œë“œ
useEffect(() => {
  const loadConfigMetadata = async () => {
    if (!selectedModel) return;

    const response = await api.resources.getConfigMetadata({ 
      model_id: selectedModel 
    });
    
    if (response.success) {
      const { rag_params, llm_judge_params } = response.data;
      setParamRanges({ rag_params, llm_judge_params });
      
      // ê¸°ë³¸ê°’ ì ìš©
      setTopK([rag_params.top_k.default]);
      setChunkSize(rag_params.chunk_size.default.toString());
      setChunkOverlap([rag_params.chunk_overlap.default]);
      setSimilarityThreshold([rag_params.similarity_threshold.default]);
      
      // LLM Judge íŒŒë¼ë¯¸í„°ë„ ë™ì  ì ìš©
      setLlmJudgeScoreThreshold(llm_judge_params.score_threshold.default);
      setLlmJudgeContextThreshold(llm_judge_params.context_recall_threshold.default);
      setLlmJudgeMinTokens(llm_judge_params.min_context_tokens.default);
    }
  };
  
  loadConfigMetadata();
}, [selectedModel]);

// Slider ì»´í¬ë„ŒíŠ¸ì— ë™ì  ë²”ìœ„ ì ìš©
<Slider
  value={topK}
  onValueChange={setTopK}
  min={paramRanges?.rag_params.top_k.min || 1}
  max={paramRanges?.rag_params.top_k.max || 20}
  step={paramRanges?.rag_params.top_k.step || 1}
  className="flex-1"
/>
```

#### c) ë°±ì—”ë“œ êµ¬í˜„

```python
# backend/api/config.py
@router.get("/config/params")
async def get_config_metadata(model_id: Optional[str] = None):
    """
    RAG ë° LLM Judge íŒŒë¼ë¯¸í„°ì˜ ìœ íš¨ ë²”ìœ„ ë°˜í™˜
    ëª¨ë¸ë³„ë¡œ ë‹¤ë¥¸ ë²”ìœ„ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŒ
    """
    # ëª¨ë¸ ì •ë³´ ì¡°íšŒ
    model = await get_model_by_id(model_id) if model_id else None
    
    # GPT-4oëŠ” context windowê°€ í¬ë¯€ë¡œ chunk_size ë²”ìœ„ê°€ ë„“ìŒ
    if model and model.name == "GPT-4o":
        chunk_size_max = 4096
    else:
        chunk_size_max = 2048
    
    return {
        "rag_params": {
            "top_k": {"min": 1, "max": 20, "default": 5, "step": 1},
            "chunk_size": {"min": 128, "max": chunk_size_max, "default": 1024, "step": 128},
            "chunk_overlap": {"min": 0, "max": 200, "default": 100, "step": 10},
            "similarity_threshold": {"min": 0.0, "max": 1.0, "default": 0.75, "step": 0.05},
            "retriever_types": ["semantic", "hybrid", "keyword"]
        },
        "llm_judge_params": {
            "score_threshold": {"min": 0.0, "max": 1.0, "default": 0.2},
            "context_recall_threshold": {"min": 0.0, "max": 1.0, "default": 0.1},
            "min_context_tokens": {"min": 10, "max": 1000, "default": 50}
        }
    }
```

**ì™„ë£Œ ê¸°ì¤€:**
- [x] API í´ë¼ì´ì–¸íŠ¸ í•¨ìˆ˜ ì¶”ê°€ âœ…
- [ ] ë°±ì—”ë“œ `/config/params` API êµ¬í˜„
- [ ] NewEvaluationPageBlue.tsxì— ë™ì  ë¡œë”© ë¡œì§ ì¶”ê°€
- [ ] ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë“¤(chunk_size, chunk_overlap ë“±)ë„ ë™ì¼í•˜ê²Œ ì ìš©

---

## ğŸ“Š ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Critical (V1.0 ë°°í¬ ì „ í•„ìˆ˜)

#### 1. LLM Judge ì•ˆì •ì„±
- [x] TypeScript íƒ€ì…ì— `raw_llm_output`, `parsing_failed` ì¶”ê°€ âœ…
- [ ] ë°±ì—”ë“œ DB ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ (`failed_cases` í…Œì´ë¸”)
- [ ] ë°±ì—”ë“œ íŒŒì‹± ì‹¤íŒ¨ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„
- [ ] í”„ë¡ íŠ¸ì—”ë“œ íŒŒì‹± ì‹¤íŒ¨ ì•Œë¦¼ UI ì¶”ê°€

#### 2. ë¹„ìš© ê´€ì œ
- [x] TypeScript `LLMPricing` íƒ€ì… ì •ì˜ ì™„ë£Œ âœ…
- [x] API í´ë¼ì´ì–¸íŠ¸ `costApi.getPricing()` ì¡´ì¬ âœ…
- [ ] ë°±ì—”ë“œ `llm_pricing` í…Œì´ë¸” ìƒì„±
- [ ] ë°±ì—”ë“œ ê°€ê²© ê´€ë¦¬ API êµ¬í˜„

### High Priority (V1.0 ê¶Œì¥)

#### 3. í‰ê°€ ì—”ì§„ ì˜¤ë¥˜ ì²˜ë¦¬
- [x] TypeScript íƒ€ì… `'retrying'` ìƒíƒœ ì¶”ê°€ âœ…
- [x] TypeScript íƒ€ì… `retry_count`, `max_retries`, `last_error` ì¶”ê°€ âœ…
- [ ] ë°±ì—”ë“œ ì¬ì‹œë„ ì •ì±… êµ¬í˜„ (Python RQ)
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ì¬ì‹œë„ ìƒíƒœ UI ì¶”ê°€

#### 4. ë¡œê¹…/ëª¨ë‹ˆí„°ë§
- [x] í”„ë¡ íŠ¸ì—”ë“œ `LogViewerPageBlue.tsx` ì™„ì„± âœ…
- [ ] ë°±ì—”ë“œ JSON ë¡œê¹… ì„¤ì •
- [ ] Prometheus + Grafana ì„¤ì • (í”„ë¡œë•ì…˜)

#### 5. í”„ë¡ íŠ¸ì—”ë“œ ìœ ì—°ì„±
- [x] API í´ë¼ì´ì–¸íŠ¸ `getConfigMetadata()` ì¶”ê°€ âœ…
- [ ] ë°±ì—”ë“œ `/config/params` API êµ¬í˜„
- [ ] NewEvaluationPageBlue ë™ì  ë¡œë”© ë¡œì§ ì¶”ê°€

### Medium Priority (V1.5)

- [ ] í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ
- [ ] ê´€ë¦¬ì í˜ì´ì§€ LLM ê°€ê²© ê´€ë¦¬ íƒ­
- [ ] ì»¤ìŠ¤í…€ ì§€í‘œ ê¸°ëŠ¥

---

## ğŸ¯ V1.0 ë°°í¬ ê¸°ì¤€

ë‹¤ìŒ í•­ëª©ì´ ëª¨ë‘ ì™„ë£Œë˜ë©´ V1.0 í”„ë¡œë•ì…˜ ë°°í¬ ê°€ëŠ¥:

1. **Critical í•­ëª© 100% ì™„ë£Œ**
   - LLM Judge íŒŒì‹± ì‹¤íŒ¨ ì²˜ë¦¬
   - LLM ê°€ê²© ì •ë³´ ê´€ë¦¬

2. **High Priority í•­ëª© 80% ì´ìƒ ì™„ë£Œ**
   - ì¬ì‹œë„ ë¡œì§ êµ¬í˜„
   - ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¶•

3. **í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼**
   - í‰ê°€ ìƒì„± â†’ ì‹¤í–‰ â†’ ì§„ë‹¨ â†’ ë¹„ìš© ì¶”ì  ì „ì²´ ì›Œí¬í”Œë¡œìš°
   - LLM Judge ìƒ˜í”Œë§ ë¹„ìš© ì ˆê° ê²€ì¦ (90% ì´ìƒ)
   - ì¬ì‹œë„ ë¡œì§ ë™ì‘ í™•ì¸

4. **ë¬¸ì„œí™” ì™„ë£Œ**
   - API ë¬¸ì„œ ìµœì‹ í™”
   - ìš´ì˜ ë§¤ë‰´ì–¼ ì‘ì„±
   - íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ ì‘ì„±

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [Backend Integration Complete Guide](./Backend-Integration-Complete-Guide.md)
- [LLM Judge Cost Optimization Backend](./LLM-Judge-Cost-Optimization-Backend.md)
- [API Specification](./API-Specification.md)
- [Production Deployment Checklist](./Production-Deployment-Checklist.md)
- [Score Analysis Algorithm](./Score-Analysis-Algorithm.md)

---

**ì´ ë¬¸ì„œëŠ” ì™¸ë¶€ ì „ë¬¸ê°€ ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, V1.0 ë°°í¬ ì „ ë°˜ë“œì‹œ ê²€í†  ë° êµ¬í˜„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.**
